{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qnJ1qJKfOvTs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qnJ1qJKfOvTs",
        "outputId": "43c79474-a98e-4570-8f68-389a7d05806b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sympy==1.12\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy==1.12) (1.3.0)\n",
            "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.9.0+cu126 requires sympy>=1.13.3, but you have sympy 1.12 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.12\n"
          ]
        }
      ],
      "source": [
        "!pip install sympy==1.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fmCucnszfgEc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmCucnszfgEc",
        "outputId": "ae7a4353-62e5-4f29-a995-3b75b421a2d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa84aaa",
      "metadata": {
        "id": "1fa84aaa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a96b806c",
      "metadata": {
        "id": "a96b806c"
      },
      "outputs": [],
      "source": [
        "#configuration for GPT model having 124 million parameters\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 256, #1024\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae719821",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ae719821",
        "outputId": "1f9471bc-31b1-48c0-c228-87ee5f641445"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntext\\ntoken id\\ntoken embedding\\nposition embedding\\ninput embedding\\ndropout\\nlayer normalization\\nself-attention\\ndropout\\nresidual connection\\nlayer normalization\\nfeed forward neural network\\ndropout\\nresidual connection\\nlayer normalization\\noutput logits\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "text\n",
        "token id\n",
        "token embedding\n",
        "position embedding\n",
        "input embedding\n",
        "dropout\n",
        "layer normalization\n",
        "self-attention\n",
        "dropout\n",
        "residual connection\n",
        "layer normalization\n",
        "feed forward neural network\n",
        "dropout\n",
        "residual connection\n",
        "layer normalization\n",
        "output logits\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d66e22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16d66e22",
        "outputId": "cfdfdcc6-21e5-4325-9797-1230c20db407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d46531",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00d46531",
        "outputId": "5d377304-7a3e-4a5b-a739-43149006dc77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'vocab_size': 50257,\n",
              " 'context_length': 256,\n",
              " 'emb_dim': 768,\n",
              " 'n_heads': 12,\n",
              " 'n_layers': 12,\n",
              " 'drop_rate': 0.1,\n",
              " 'qkv_bias': False}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#class for multi head attention_tags\n",
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_head\"\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_q = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_k = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_v = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = torch.nn.Linear(d_out, d_out)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        key = self.W_k(x)\n",
        "        query = self.W_q(x)\n",
        "        value = self.W_v(x)\n",
        "\n",
        "        #reshaping key, query, value as each token with 12 heads and each head with 64 dimensions\n",
        "        key = key.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        query = query.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        value = value.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        #transposing to get dimensions as batch size, each head with num_tokens and each token with head_dim (b, num_heads, num_tokens, head_dim)\n",
        "        key = key.transpose(1,2)\n",
        "        query = query.transpose(1,2)\n",
        "        value = value.transpose(1,2)\n",
        "\n",
        "        #calculating attention score by multiplication of query and key transpose (num_tokens, head_dim) @ (head_dim, num_tokens) = (num_tokens, num_tokens)\n",
        "        attn_scores = query @ key.transpose(2,3)\n",
        "\n",
        "        #creating mask to make the future tokens to have -inf attention score and after softmax will become zero as probability\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores = attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        #attention score is divided by sqrt of key dimension to avoid large values and then softmax is applied to get normalize weights\n",
        "        attn_weights = torch.softmax(attn_scores / key.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        #multiplying attention weights with value to get context vector (b, num_heads, num_tokens, num_tokens) * (b, num_heads, num_tokens, head_dim) = (b, num_heads, num_tokens, head_dim)\n",
        "        context_vector = (attn_weights @ value).transpose(1,2)\n",
        "        context_vector = context_vector.contiguous().view(b, num_tokens, d_in)\n",
        "        context_vector = self.out_proj(context_vector)\n",
        "\n",
        "        return context_vector\n",
        "\n",
        "#class for transformer block\n",
        "class  TransformerBlock(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttention(d_in=cfg['emb_dim'], d_out=cfg['emb_dim'], context_length=cfg['context_length'],\n",
        "                                    num_heads=cfg['n_heads'], dropout=cfg['drop_rate'], qkv_bias=cfg['qkv_bias'])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 =  LayerNorm(cfg['emb_dim'])\n",
        "        self.norm2 =  LayerNorm(cfg['emb_dim'])\n",
        "        self.drop_shortcut = torch.nn.Dropout(cfg['drop_rate'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.attn(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "        return x\n",
        "\n",
        "#class for layer normalization\n",
        "class  LayerNorm(torch.nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = torch.nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = torch.nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * x_norm + self.shift\n",
        "\n",
        "#class for GELU activaton function\n",
        "class GELU(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) *(x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "#class for feed forward neural network\n",
        "class FeedForward(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(cfg['emb_dim'], 4*cfg['emb_dim']),\n",
        "            GELU(),\n",
        "            torch.nn.Linear(4*cfg['emb_dim'], cfg['emb_dim'])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class GPTmodel(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.token_emb = torch.nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
        "        self.pos_emb = torch.nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
        "        self.drop_emb = torch.nn.Dropout(cfg['drop_rate'])\n",
        "\n",
        "        self.trf_blocks = torch.nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg['n_layers'])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
        "        self.out_head = torch.nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_length = in_idx.shape\n",
        "        token_embeds = self.token_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_length, device=in_idx.device))\n",
        "        x = token_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits #shape: (batch_size, seq_length, vocab_size)\n",
        "GPT_CONFIG_124M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99a75443",
      "metadata": {
        "id": "99a75443"
      },
      "outputs": [],
      "source": [
        "# function to convert text to token ids and vice versa\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff46831",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ff46831",
        "outputId": "089ce12e-a926-445f-ad1f-ac735939d220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[15496,     0,   314,   716]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 4])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text1 = 'Hello! I am'\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "input_ids=text_to_token_ids(text1, tokenizer)\n",
        "print(input_ids)\n",
        "input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a13cd6",
      "metadata": {
        "id": "08a13cd6"
      },
      "outputs": [],
      "source": [
        "#generating text from the model\n",
        "def generate_text(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None: #taking top k logits and setting rest to -inf\n",
        "            top_logits, _ = torch.topk(logits, top_k, dim=-1)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        if temperature>0.0: #applying temperature scaling and sampling from the distribution\n",
        "            logits = logits/temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1) #(batch_size, 1)\n",
        "        else:\n",
        "            next_token = torch.argmax(logits, dim=-1, keepdim=True) #(batch, 1)\n",
        "\n",
        "        if next_token == eos_id: #stop generation if end of sequence token is generated\n",
        "            break\n",
        "\n",
        "        idx = torch.cat((idx, next_token), dim=1) #(batch,n_tokens+1) concatenating the new token to the existing sequence\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "621cec8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "621cec8b",
        "outputId": "60bda97e-37e2-4a60-87d1-2318d9b9ed89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[15496,     0,   314,   716, 13240, 11381,  4307,  7640, 33491, 12254,\n",
            "         26050,  8942, 44168, 35735]])\n",
            "Hello! I am Laur inhab Distrinereplacefly279 Burn issuerurnal\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "model.eval() # set the model to evaluation mode , stops acting like training, dropout works as identity\n",
        "result_tokens = generate_text(model=model, idx=input_ids, max_new_tokens=10, context_size=GPT_CONFIG_124M['context_length'])\n",
        "print(result_tokens)\n",
        "decoded_output = tokenizer.decode(result_tokens[0].tolist())\n",
        "print(decoded_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9566a479",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9566a479",
        "outputId": "983128f8-2e7e-4396-e53b-2b26d633bedc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.eot_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d05d60",
      "metadata": {
        "id": "15d05d60"
      },
      "outputs": [],
      "source": [
        "#function to generate and print text from the model\n",
        "def generate_and_print(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_tokens = generate_text(model, encoded, max_new_tokens=50, context_size=context_size, temperature=0.8, top_k=50, eos_id=tokenizer.eot_token)\n",
        "    decoded_text = token_ids_to_text(generated_tokens, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\",\" \"))\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca2d0f5b",
      "metadata": {
        "id": "ca2d0f5b"
      },
      "outputs": [],
      "source": [
        "#will create now dataset and dataloader using bpe_tokenizer and the verdict text file\n",
        "#we will use this class in dataloader to create batches of data\n",
        "class GPTDatasetv1:\n",
        "    def __init__(self, text, tokenizer, max_len, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "        token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0, len(token_ids)-max_len, stride):\n",
        "            input_id = token_ids[i:i+max_len]\n",
        "            target_id = token_ids[i+1:i+max_len+1]\n",
        "            self.input_ids.append(torch.tensor(input_id))\n",
        "            self.target_ids.append(torch.tensor(target_id))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "#dataloader function to create batches of data\n",
        "def create_dataloaderv1(text, batch_size=4, max_len=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset1 = GPTDatasetv1(text, tokenizer, max_len, stride)\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d350cdcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d350cdcc",
        "outputId": "92febb67-7df5-4162-9f40-4d2cd972d966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total tokens: 5145, total characters: 20479\n"
          ]
        }
      ],
      "source": [
        "#Dataset is now stored in variable content\n",
        "# with open(\"/content/drive/MyDrive/Dataset/the-verdict.txt\") as file:\n",
        "with open(\"/content/drive/MyDrive/Khanakh/Dataset/the-verdict.txt\") as file:\n",
        "    content = file.read()\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "total_tokens = len(tokenizer.encode(content))\n",
        "total_characters = len(content)\n",
        "print(f\"total tokens: {total_tokens}, total characters: {total_characters}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ecd329",
      "metadata": {
        "id": "b7ecd329"
      },
      "outputs": [],
      "source": [
        "#training and validation dataloaders\n",
        "train_ratio = 0.9\n",
        "tokens = tokenizer.encode(content)\n",
        "split = int(train_ratio * len(tokens))\n",
        "\n",
        "train_tokens = tokens[:split]\n",
        "val_tokens = tokens[split:]\n",
        "\n",
        "train_data = tokenizer.decode(train_tokens)\n",
        "val_data = tokenizer.decode(val_tokens)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataloader = create_dataloaderv1(text=train_data, batch_size=2, max_len=GPT_CONFIG_124M['context_length'],\n",
        "                                    stride=GPT_CONFIG_124M['context_length'], shuffle=True, drop_last=True, num_workers=0)\n",
        "\n",
        "val_dataloader = create_dataloaderv1(text=val_data, batch_size=2, max_len=GPT_CONFIG_124M['context_length'],\n",
        "                                    stride=GPT_CONFIG_124M['context_length'], shuffle=False, drop_last=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204e78f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "204e78f3",
        "outputId": "00beccb8-a485-4ac0-8392-8699f96479b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "for x,y in train_dataloader:\n",
        "    print(x.shape, y.shape)\n",
        "#this shows us total lines as total number of batches with each batch having 2 samples (input and target) of (2, 1024) shape which means batch size (sequences) is 2 and each sample has 1024 tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1de9fb8",
      "metadata": {
        "id": "c1de9fb8"
      },
      "outputs": [],
      "source": [
        "#function to calculate loss using cross entropy loss per batch\n",
        "def compute_loss(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "#calculate average loss for specified number of batches from dataloader\n",
        "def calc_loss_loader(dataloader, model, device, num_batches=None):\n",
        "    total_loss = 0\n",
        "    if len(dataloader) == 0:\n",
        "        return float('nan')\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(dataloader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(dataloader))\n",
        "        for i, (input_batch, target_batch) in enumerate(dataloader):\n",
        "            if i < num_batches:\n",
        "                loss = compute_loss(input_batch, target_batch, model, device)\n",
        "                total_loss += loss.item()\n",
        "            else:\n",
        "                break\n",
        "        avg_loss = total_loss / num_batches\n",
        "    return avg_loss\n",
        "\n",
        "#function to calculate training and validation loss at regular intervals(batches/eval_iter)\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68fdd1c9",
      "metadata": {
        "id": "68fdd1c9"
      },
      "outputs": [],
      "source": [
        "#training loop for llm model\n",
        "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
        "    #initialize list to track training and validation loss and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [],[],[]\n",
        "    tokens_seen, global_step = 0, 0\n",
        "\n",
        "    #training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train() #set the model to training mode\n",
        "        for (input_batch, target_batch) in train_loader:\n",
        "            optimizer.zero_grad() #clear previous gradients\n",
        "            loss = compute_loss(input_batch, target_batch, model, device)\n",
        "            loss.backward() #backpropagation (calculate loss backwards)\n",
        "            optimizer.step() #update model parameters\n",
        "            tokens_seen += input_batch.numel() #number of tokens seen so far\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Epoch {epoch+1}, step {global_step}: train_loss = {train_loss:.3f}, val_loss = {val_loss:.3f}, tokens_seen = {tokens_seen}\")\n",
        "\n",
        "        generate_and_print(model, tokenizer, device, start_context)\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c1e23d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38c1e23d",
        "outputId": "5d6829a6-e367-4a09-da15-29e91e18f073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, step 2: train_loss = 8.618, val_loss = 8.164, tokens_seen = 1024\n",
            "Epoch 1, step 4: train_loss = 7.466, val_loss = 7.590, tokens_seen = 2048\n",
            "Epoch 1, step 6: train_loss = 8.427, val_loss = 8.799, tokens_seen = 3072\n",
            "Epoch 1, step 8: train_loss = 8.495, val_loss = 8.532, tokens_seen = 4096\n",
            "Every effort moves you fact not eyes would in..I it her- that And ofis.. in him he. a in not who notthe would St that it been. G G--.roud? he her\".I in out- he It painting\n",
            "Epoch 2, step 10: train_loss = 7.379, val_loss = 8.328, tokens_seen = 5120\n",
            "Epoch 2, step 12: train_loss = 7.697, val_loss = 8.376, tokens_seen = 6144\n",
            "Epoch 2, step 14: train_loss = 6.972, val_loss = 8.505, tokens_seen = 7168\n",
            "Epoch 2, step 16: train_loss = 6.948, val_loss = 8.401, tokens_seen = 8192\n",
            "Epoch 2, step 18: train_loss = 6.676, val_loss = 8.397, tokens_seen = 9216\n",
            "Every effort moves you my my\":. was he. it.. it.--burn to the as had. a. to I of with was't all-- my, it was to work I I had it it. about\" I my no a a you\n",
            "Epoch 3, step 20: train_loss = 6.829, val_loss = 8.511, tokens_seen = 10240\n",
            "Epoch 3, step 22: train_loss = 6.807, val_loss = 8.586, tokens_seen = 11264\n",
            "Epoch 3, step 24: train_loss = 6.388, val_loss = 8.484, tokens_seen = 12288\n",
            "Epoch 3, step 26: train_loss = 6.383, val_loss = 8.366, tokens_seen = 13312\n",
            "Every effort moves you, their the--,\"   roud had a, with , to Mrs the of, St the my he it . the, a and. under a and of   just?.,  the by a of,, he\n",
            "Epoch 4, step 28: train_loss = 6.555, val_loss = 8.388, tokens_seen = 14336\n",
            "Epoch 4, step 30: train_loss = 6.054, val_loss = 8.412, tokens_seen = 15360\n",
            "Epoch 4, step 32: train_loss = 6.377, val_loss = 8.237, tokens_seen = 16384\n",
            "Epoch 4, step 34: train_loss = 6.301, val_loss = 8.113, tokens_seen = 17408\n",
            "Epoch 4, step 36: train_loss = 6.055, val_loss = 8.040, tokens_seen = 18432\n",
            "Every effort moves you theI that and and.-- heI you I his me, how, he me to--'t't.., you to-- him was was me and to\"\" her one and't to.\" the and,I was he: was\n",
            "Epoch 5, step 38: train_loss = 6.361, val_loss = 8.009, tokens_seen = 19456\n",
            "Epoch 5, step 40: train_loss = 6.266, val_loss = 8.050, tokens_seen = 20480\n",
            "Epoch 5, step 42: train_loss = 6.422, val_loss = 8.028, tokens_seen = 21504\n",
            "Epoch 5, step 44: train_loss = 6.095, val_loss = 7.962, tokens_seen = 22528\n",
            "Every effort moves you-- with with the. have. of so it,\" his,,., and, he a and the, he,\"., hadis the G a a, in a of the.  , my in what, own, my of\n",
            "Epoch 6, step 46: train_loss = 6.099, val_loss = 7.948, tokens_seen = 23552\n",
            "Epoch 6, step 48: train_loss = 6.033, val_loss = 8.071, tokens_seen = 24576\n",
            "Epoch 6, step 50: train_loss = 6.013, val_loss = 8.125, tokens_seen = 25600\n",
            "Epoch 6, step 52: train_loss = 5.954, val_loss = 8.061, tokens_seen = 26624\n",
            "Epoch 6, step 54: train_loss = 6.017, val_loss = 7.919, tokens_seen = 27648\n",
            "Every effort moves you when he up her was he he the. in.  .. (. the the his\" the, him in his by me,, to the  I his was.\" with I the when.\"-- the   I his on not\n",
            "Epoch 7, step 56: train_loss = 6.106, val_loss = 7.887, tokens_seen = 28672\n",
            "Epoch 7, step 58: train_loss = 5.915, val_loss = 7.859, tokens_seen = 29696\n",
            "Epoch 7, step 60: train_loss = 5.849, val_loss = 7.760, tokens_seen = 30720\n",
            "Epoch 7, step 62: train_loss = 5.828, val_loss = 7.665, tokens_seen = 31744\n",
            "Every effort moves you on to  after the. St theis. _ , one to his. to,'s. the\". not him, him to one.  foundations--. I it to-- to and my to to, you.. But till\n",
            "Epoch 8, step 64: train_loss = 5.939, val_loss = 7.625, tokens_seen = 32768\n",
            "Epoch 8, step 66: train_loss = 5.723, val_loss = 7.678, tokens_seen = 33792\n",
            "Epoch 8, step 68: train_loss = 5.719, val_loss = 7.711, tokens_seen = 34816\n",
            "Epoch 8, step 70: train_loss = 5.864, val_loss = 7.776, tokens_seen = 35840\n",
            "Epoch 8, step 72: train_loss = 5.706, val_loss = 7.754, tokens_seen = 36864\n",
            "Every effort moves you her his not \"\" point,.I had one had---- a   wife he had a I of of,\" the And---.\"  is. G-- hisI the  first; a \" art up as me\n",
            "Epoch 9, step 74: train_loss = 5.886, val_loss = 7.733, tokens_seen = 37888\n",
            "Epoch 9, step 76: train_loss = 5.838, val_loss = 7.721, tokens_seen = 38912\n",
            "Epoch 9, step 78: train_loss = 5.711, val_loss = 7.671, tokens_seen = 39936\n",
            "Epoch 9, step 80: train_loss = 5.709, val_loss = 7.595, tokens_seen = 40960\n",
            "Every effort moves you. \"  ,--'s Mrs,---- to one him was Mrs,-- had in----,-- had in_, had a. . be own it it. was she my-- I, was a . show,.\"\n",
            "Epoch 10, step 82: train_loss = 5.820, val_loss = 7.592, tokens_seen = 41984\n",
            "Epoch 10, step 84: train_loss = 5.525, val_loss = 7.594, tokens_seen = 43008\n",
            "Epoch 10, step 86: train_loss = 5.784, val_loss = 7.578, tokens_seen = 44032\n",
            "Epoch 10, step 88: train_loss = 5.860, val_loss = 7.576, tokens_seen = 45056\n",
            "Epoch 10, step 90: train_loss = 5.593, val_loss = 7.516, tokens_seen = 46080\n",
            "Every effort moves you been  \" up of.  is a I of in the    is a Th\"  Well.The .   wall one.\"--  I a  tricks, to theI-- . \n"
          ]
        }
      ],
      "source": [
        "#train the model\n",
        "torch.manual_seed(123)\n",
        "model = GPTmodel(GPT_CONFIG_124M).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.004, weight_decay=0.01)\n",
        "num_epochs = 10\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model(model=model, train_loader=train_dataloader, val_loader=val_dataloader, optimizer=optimizer,\n",
        "                                                    device=device, num_epochs=num_epochs, eval_freq=4, eval_iter=4,\n",
        "                                                    start_context=\"Every effort moves you\", tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df940976",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df940976",
        "outputId": "0a2a94fa-427f-49b6-85ce-11c7024ae05e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Every effort moves you the his the,, me, theYes the  wife, of have. \" it of.   \" I to the    little, on,'s you.   Oh the,. Yes he- the\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "generate_and_print(model, tokenizer, device, start_context='Every effort moves you')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oPAkIgvZXSS8",
      "metadata": {
        "id": "oPAkIgvZXSS8"
      },
      "source": [
        "Saving and loading model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87ea7fc",
      "metadata": {
        "id": "e87ea7fc"
      },
      "outputs": [],
      "source": [
        "#saves the model weight to given path\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "torch.save(model.state_dict(), 'gpt2_rand_weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b920df2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b920df2",
        "outputId": "59f28431-1dda-4def-91d1-b93b86b86de8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load the model weights into new gptmodel model instance\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load('gpt2_rand_weights.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a65a4b1f",
      "metadata": {
        "id": "a65a4b1f"
      },
      "outputs": [],
      "source": [
        "#to save both model weights and optimizer parameters\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2023c784",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2023c784",
        "outputId": "e76028ae-cdee-47ac-d19d-9e5ddb16e24d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTmodel(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loads both model weights and optimizer parameter for each weight\n",
        "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c284f8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c284f8d",
        "outputId": "eaa0695a-f9fe-4b1e-f50f-5af4d0610b22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "162419712"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "total_params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u9HfFvniWisZ",
      "metadata": {
        "id": "u9HfFvniWisZ"
      },
      "source": [
        "# Loading Pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "590e4666",
      "metadata": {
        "id": "590e4666"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46536875",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "8e8e57657d01444fb53099dd1ad9e91f",
            "06c60e5ddd2a44749be0cf496728bd41",
            "c52014e636644a8bbf36af7a0e675cfd",
            "6602fc5721c445a3b93a9beaae2be4a1",
            "51306772f89d42ccbf94a28c659a98b4",
            "6cc8d444b7414eb1b091f93bb39a66dd",
            "a27d25b2c08845f18cc3eab0aa1c0675",
            "1e3509c630af4e1d93537834766f78d2",
            "9725d1c35c8c479a9ce5c049f88ffe80",
            "1ddfab07551c44df87e1f8faddacdeee",
            "e6639aa8a55b4b77994361650a381a9b",
            "3a6f8f46126e4cb78aaedcd70e74a200",
            "a1654069382b4c04ad5ab480eaaaba51",
            "4cd195d22eed491f98bdc63b6d851a4f",
            "fc0585a1666d4b0a8f5c6c0fca74d18b",
            "4dc468f4667d460c82dd17f15c0f0857",
            "5761439544f44d3984fbbc6e9573c9e9",
            "d6db2b44f7674bb09ad100c4464a8776",
            "1e7d69871aeb44a284e28ff08de32986",
            "f8998c0820454e6b8029a22d97b4dced",
            "5e590edaaf634a869031e4c0d4f25599",
            "bef84d2ca11042ceaa7b08bcefb5e838",
            "9e17e99481464471b0d5622b2860b2d4",
            "a6aca18f95f6437fb83e9913be450adf",
            "8d536187aa8d4bc0b54a78bc489c2c90",
            "bcb05f1d439c4b07ae5984a8f85bb6cf",
            "90e3c047db144ae7bca91e7b971ee2c0",
            "c2d24b5281004f7ca9775ac59892a264",
            "f56504e73df94cc8a2adefda81cc6f24",
            "c3ea7d7d619f4754946c58d9955d6fd6",
            "cd384d195df64b9cb6d34e29fd85d66b",
            "4bf34e95ca334295a3ee5063f49dc56b",
            "06d276641e77412cbc372d27142e1f55"
          ]
        },
        "id": "46536875",
        "outputId": "721926cd-396b-43ef-acf8-6c56d6a31cf4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e8e57657d01444fb53099dd1ad9e91f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a6f8f46126e4cb78aaedcd70e74a200",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e17e99481464471b0d5622b2860b2d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#load pretrained gpt2 model and tokenizer from huggingface transformers library\n",
        "model_name = 'gpt2'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model_new = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3def69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce3def69",
        "outputId": "84548c9e-118e-4241-9973-64acac28d84a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transformer.wte.weight  torch.Size([50257, 768])\n",
            "transformer.wpe.weight  torch.Size([1024, 768])\n",
            "transformer.h.0.ln_1.weight  torch.Size([768])\n",
            "transformer.h.0.ln_1.bias  torch.Size([768])\n",
            "transformer.h.0.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.0.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.0.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.0.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.0.ln_2.weight  torch.Size([768])\n",
            "transformer.h.0.ln_2.bias  torch.Size([768])\n",
            "transformer.h.0.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.0.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.0.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.0.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.1.ln_1.weight  torch.Size([768])\n",
            "transformer.h.1.ln_1.bias  torch.Size([768])\n",
            "transformer.h.1.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.1.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.1.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.1.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.1.ln_2.weight  torch.Size([768])\n",
            "transformer.h.1.ln_2.bias  torch.Size([768])\n",
            "transformer.h.1.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.1.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.1.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.1.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.2.ln_1.weight  torch.Size([768])\n",
            "transformer.h.2.ln_1.bias  torch.Size([768])\n",
            "transformer.h.2.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.2.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.2.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.2.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.2.ln_2.weight  torch.Size([768])\n",
            "transformer.h.2.ln_2.bias  torch.Size([768])\n",
            "transformer.h.2.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.2.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.2.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.2.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.3.ln_1.weight  torch.Size([768])\n",
            "transformer.h.3.ln_1.bias  torch.Size([768])\n",
            "transformer.h.3.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.3.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.3.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.3.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.3.ln_2.weight  torch.Size([768])\n",
            "transformer.h.3.ln_2.bias  torch.Size([768])\n",
            "transformer.h.3.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.3.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.3.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.3.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.4.ln_1.weight  torch.Size([768])\n",
            "transformer.h.4.ln_1.bias  torch.Size([768])\n",
            "transformer.h.4.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.4.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.4.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.4.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.4.ln_2.weight  torch.Size([768])\n",
            "transformer.h.4.ln_2.bias  torch.Size([768])\n",
            "transformer.h.4.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.4.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.4.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.4.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.5.ln_1.weight  torch.Size([768])\n",
            "transformer.h.5.ln_1.bias  torch.Size([768])\n",
            "transformer.h.5.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.5.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.5.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.5.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.5.ln_2.weight  torch.Size([768])\n",
            "transformer.h.5.ln_2.bias  torch.Size([768])\n",
            "transformer.h.5.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.5.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.5.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.5.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.6.ln_1.weight  torch.Size([768])\n",
            "transformer.h.6.ln_1.bias  torch.Size([768])\n",
            "transformer.h.6.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.6.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.6.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.6.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.6.ln_2.weight  torch.Size([768])\n",
            "transformer.h.6.ln_2.bias  torch.Size([768])\n",
            "transformer.h.6.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.6.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.6.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.6.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.7.ln_1.weight  torch.Size([768])\n",
            "transformer.h.7.ln_1.bias  torch.Size([768])\n",
            "transformer.h.7.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.7.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.7.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.7.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.7.ln_2.weight  torch.Size([768])\n",
            "transformer.h.7.ln_2.bias  torch.Size([768])\n",
            "transformer.h.7.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.7.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.7.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.7.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.8.ln_1.weight  torch.Size([768])\n",
            "transformer.h.8.ln_1.bias  torch.Size([768])\n",
            "transformer.h.8.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.8.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.8.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.8.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.8.ln_2.weight  torch.Size([768])\n",
            "transformer.h.8.ln_2.bias  torch.Size([768])\n",
            "transformer.h.8.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.8.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.8.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.8.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.9.ln_1.weight  torch.Size([768])\n",
            "transformer.h.9.ln_1.bias  torch.Size([768])\n",
            "transformer.h.9.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.9.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.9.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.9.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.9.ln_2.weight  torch.Size([768])\n",
            "transformer.h.9.ln_2.bias  torch.Size([768])\n",
            "transformer.h.9.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.9.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.9.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.9.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.10.ln_1.weight  torch.Size([768])\n",
            "transformer.h.10.ln_1.bias  torch.Size([768])\n",
            "transformer.h.10.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.10.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.10.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.10.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.10.ln_2.weight  torch.Size([768])\n",
            "transformer.h.10.ln_2.bias  torch.Size([768])\n",
            "transformer.h.10.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.10.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.10.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.10.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.11.ln_1.weight  torch.Size([768])\n",
            "transformer.h.11.ln_1.bias  torch.Size([768])\n",
            "transformer.h.11.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.11.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.11.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.11.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.11.ln_2.weight  torch.Size([768])\n",
            "transformer.h.11.ln_2.bias  torch.Size([768])\n",
            "transformer.h.11.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.11.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.11.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.11.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.ln_f.weight  torch.Size([768])\n",
            "transformer.ln_f.bias  torch.Size([768])\n",
            "lm_head.weight  torch.Size([50257, 768])\n"
          ]
        }
      ],
      "source": [
        "param = model_new.state_dict()\n",
        "for key in param:\n",
        "  print(key, \"\", param[key].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5cd451",
      "metadata": {
        "id": "4c5cd451"
      },
      "outputs": [],
      "source": [
        "#configuration for GPT model having 124 million parameters\n",
        "NEW_CONFIG = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.2,\n",
        "    \"qkv_bias\": True\n",
        "}\n",
        "gpt = GPTmodel(NEW_CONFIG)\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OGYHFyv_oaUk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGYHFyv_oaUk",
        "outputId": "097f6633-8508-4dc0-c296-e667213a68ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([768, 2304])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_new.transformer.h[0].mlp.c_proj.bias[:5]\n",
        "len(model_new.transformer.h)\n",
        "model_new.transformer.h[0].attn.c_attn.weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-OC5FNVjfQCM",
      "metadata": {
        "id": "-OC5FNVjfQCM"
      },
      "outputs": [],
      "source": [
        "def load_weights_into_gpt(gpt, model_new):\n",
        "  with torch.no_grad():\n",
        "    gpt.token_emb.weight.copy_(model_new.transformer.wte.weight)\n",
        "    gpt.pos_emb.weight.copy_(model_new.transformer.wpe.weight)\n",
        "\n",
        "    for i in range(len(model_new.transformer.h)):\n",
        "\n",
        "      qkv_w = model_new.transformer.h[i].attn.c_attn.weight\n",
        "      q_w, k_w, v_w = torch.split(qkv_w,gpt.trf_blocks[i].attn.W_q.weight.shape[0],dim=-1)\n",
        "      gpt.trf_blocks[i].attn.W_q.weight.copy_(q_w.T)\n",
        "      gpt.trf_blocks[i].attn.W_k.weight.copy_(k_w.T)\n",
        "      gpt.trf_blocks[i].attn.W_v.weight.copy_(v_w.T)\n",
        "\n",
        "      qkv_b = model_new.transformer.h[i].attn.c_attn.bias\n",
        "      q_b, k_b, v_b = torch.split(qkv_b,gpt.trf_blocks[i].attn.W_q.bias.shape[0],dim=-1)\n",
        "      gpt.trf_blocks[i].attn.W_q.bias.copy_(q_b)\n",
        "      gpt.trf_blocks[i].attn.W_k.bias.copy_(k_b)\n",
        "      gpt.trf_blocks[i].attn.W_v.bias.copy_(v_b)\n",
        "\n",
        "      gpt.trf_blocks[i].attn.out_proj.weight.copy_(model_new.transformer.h[i].attn.c_proj.weight.T)\n",
        "      gpt.trf_blocks[i].attn.out_proj.bias.copy_(model_new.transformer.h[i].attn.c_proj.bias)\n",
        "\n",
        "      gpt.trf_blocks[i].ff.layers[0].weight.copy_(model_new.transformer.h[i].mlp.c_fc.weight.T)\n",
        "      gpt.trf_blocks[i].ff.layers[0].bias.copy_(model_new.transformer.h[i].mlp.c_fc.bias)\n",
        "      gpt.trf_blocks[i].ff.layers[2].weight.copy_(model_new.transformer.h[i].mlp.c_proj.weight.T)\n",
        "      gpt.trf_blocks[i].ff.layers[2].bias.copy_(model_new.transformer.h[i].mlp.c_proj.bias)\n",
        "\n",
        "      gpt.trf_blocks[i].norm1.scale.copy_(model_new.transformer.h[i].ln_1.weight)\n",
        "      gpt.trf_blocks[i].norm1.shift.copy_(model_new.transformer.h[i].ln_1.bias)\n",
        "      gpt.trf_blocks[i].norm2.scale.copy_(model_new.transformer.h[i].ln_2.weight)\n",
        "      gpt.trf_blocks[i].norm2.shift.copy_(model_new.transformer.h[i].ln_2.bias)\n",
        "\n",
        "    gpt.final_norm.scale.copy_(model_new.transformer.ln_f.weight)\n",
        "    gpt.final_norm.shift.copy_(model_new.transformer.ln_f.bias)\n",
        "    gpt.out_head.weight.copy_(model_new.transformer.wte.weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kFvsMf8Qvpmm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFvsMf8Qvpmm",
        "outputId": "94542317-afe8-4568-9fe8-15399446d6a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTmodel(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_weights_into_gpt(gpt,model_new)\n",
        "gpt.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pLmL5q3mH58d",
      "metadata": {
        "id": "pLmL5q3mH58d"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WsnBSlMsvpj2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsnBSlMsvpj2",
        "outputId": "80465502-27ed-4666-b501-b9e55964ffbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Every effort moves you as far as the eye can see. (That's because you're not going to be able to see it all.) I think the most interesting thing about this is that there's an easy way to avoid it. You can get that with a couple\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "generated_tokens = generate_text(gpt, text_to_token_ids(\"Every effort moves you\", tokenizer).to(device), max_new_tokens=50,\n",
        "                                context_size=NEW_CONFIG[\"context_length\"], temperature=0.8, top_k=50, eos_id=tokenizer.eot_token)\n",
        "\n",
        "output = token_ids_to_text(generated_tokens, tokenizer)\n",
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06c60e5ddd2a44749be0cf496728bd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc8d444b7414eb1b091f93bb39a66dd",
            "placeholder": "​",
            "style": "IPY_MODEL_a27d25b2c08845f18cc3eab0aa1c0675",
            "value": "config.json: 100%"
          }
        },
        "06d276641e77412cbc372d27142e1f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ef41f8bc67f46b998f2e86b30a721b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bd31081752c4131bae2de20ec7fa631": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_935b4863bde64be484353a0651cad300",
            "placeholder": "​",
            "style": "IPY_MODEL_fac80442e679418a8a8ad8040ae17419",
            "value": " 124/124 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "1ddfab07551c44df87e1f8faddacdeee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e3509c630af4e1d93537834766f78d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e7d69871aeb44a284e28ff08de32986": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2339af9d03e64857b2ef7334808d41de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d7c1242496b4f859092c717e38007f1",
            "placeholder": "​",
            "style": "IPY_MODEL_d2510b15e4d64aff92270b0a9daec0f6",
            "value": " 718/718 [00:00&lt;00:00, 61.3kB/s]"
          }
        },
        "3135daff6086420599783fe23c179a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3215099272cd451f92a85e857f678517",
            "placeholder": "​",
            "style": "IPY_MODEL_56785f833b504888a02f70a165feff56",
            "value": "model.safetensors: 100%"
          }
        },
        "3215099272cd451f92a85e857f678517": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6f8f46126e4cb78aaedcd70e74a200": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1654069382b4c04ad5ab480eaaaba51",
              "IPY_MODEL_4cd195d22eed491f98bdc63b6d851a4f",
              "IPY_MODEL_fc0585a1666d4b0a8f5c6c0fca74d18b"
            ],
            "layout": "IPY_MODEL_4dc468f4667d460c82dd17f15c0f0857"
          }
        },
        "3d7c1242496b4f859092c717e38007f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bf34e95ca334295a3ee5063f49dc56b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd195d22eed491f98bdc63b6d851a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e7d69871aeb44a284e28ff08de32986",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8998c0820454e6b8029a22d97b4dced",
            "value": 548105171
          }
        },
        "4dc468f4667d460c82dd17f15c0f0857": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51306772f89d42ccbf94a28c659a98b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52fcc6d2d930436e8cf575971066e87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "555875eb8c0d43d7992017c3e58870e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdc609ea96de493899368ee46a102e66",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52fcc6d2d930436e8cf575971066e87e",
            "value": 124
          }
        },
        "56785f833b504888a02f70a165feff56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5761439544f44d3984fbbc6e9573c9e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e590edaaf634a869031e4c0d4f25599": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f18c5e292e4aa7a51140fcddbf62a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6602fc5721c445a3b93a9beaae2be4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ddfab07551c44df87e1f8faddacdeee",
            "placeholder": "​",
            "style": "IPY_MODEL_e6639aa8a55b4b77994361650a381a9b",
            "value": " 665/665 [00:00&lt;00:00, 77.1kB/s]"
          }
        },
        "6884389ebba849ef82f965e955052578": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3135daff6086420599783fe23c179a97",
              "IPY_MODEL_82118123cc1043ff9be9ad6f72458c65",
              "IPY_MODEL_addbf946fe8247b0854b2b9af6fdad8d"
            ],
            "layout": "IPY_MODEL_c82a7f27161d4e6fb8d04414dd241466"
          }
        },
        "6a7b87f46bd74545936c9cc4bbf7a438": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c54fc0852ce44be83231bb7ae861147": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c55637115864b61b6f16d09c21e2a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cc8d444b7414eb1b091f93bb39a66dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75300d363b114a6084a8e501126a9897": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b137299d575c45a195e27a030b3e0c48",
            "max": 718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9aa7f0a9a164491196eace5e72a363fa",
            "value": 718
          }
        },
        "754d6264dc654d5086ae8136f4fae5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7667127cc244462886eaffe04c0fda8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9b81007480c4318ae74291e48fc3a04",
              "IPY_MODEL_75300d363b114a6084a8e501126a9897",
              "IPY_MODEL_2339af9d03e64857b2ef7334808d41de"
            ],
            "layout": "IPY_MODEL_fafa39a47cfc48f1b20d02ea8a4d47dd"
          }
        },
        "7dec8d1da1224301add6dc3caa044b39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82118123cc1043ff9be9ad6f72458c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dec8d1da1224301add6dc3caa044b39",
            "max": 1519984962,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c55637115864b61b6f16d09c21e2a9a",
            "value": 1519984962
          }
        },
        "8d536187aa8d4bc0b54a78bc489c2c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3ea7d7d619f4754946c58d9955d6fd6",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd384d195df64b9cb6d34e29fd85d66b",
            "value": 124
          }
        },
        "8e8e57657d01444fb53099dd1ad9e91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06c60e5ddd2a44749be0cf496728bd41",
              "IPY_MODEL_c52014e636644a8bbf36af7a0e675cfd",
              "IPY_MODEL_6602fc5721c445a3b93a9beaae2be4a1"
            ],
            "layout": "IPY_MODEL_51306772f89d42ccbf94a28c659a98b4"
          }
        },
        "90e3c047db144ae7bca91e7b971ee2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "935b4863bde64be484353a0651cad300": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9725d1c35c8c479a9ce5c049f88ffe80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9aa7f0a9a164491196eace5e72a363fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e17e99481464471b0d5622b2860b2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6aca18f95f6437fb83e9913be450adf",
              "IPY_MODEL_8d536187aa8d4bc0b54a78bc489c2c90",
              "IPY_MODEL_bcb05f1d439c4b07ae5984a8f85bb6cf"
            ],
            "layout": "IPY_MODEL_90e3c047db144ae7bca91e7b971ee2c0"
          }
        },
        "a1654069382b4c04ad5ab480eaaaba51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5761439544f44d3984fbbc6e9573c9e9",
            "placeholder": "​",
            "style": "IPY_MODEL_d6db2b44f7674bb09ad100c4464a8776",
            "value": "model.safetensors: 100%"
          }
        },
        "a27d25b2c08845f18cc3eab0aa1c0675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3242053e6404ba0bae126ecc5596137": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6aca18f95f6437fb83e9913be450adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2d24b5281004f7ca9775ac59892a264",
            "placeholder": "​",
            "style": "IPY_MODEL_f56504e73df94cc8a2adefda81cc6f24",
            "value": "generation_config.json: 100%"
          }
        },
        "addbf946fe8247b0854b2b9af6fdad8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3242053e6404ba0bae126ecc5596137",
            "placeholder": "​",
            "style": "IPY_MODEL_6a7b87f46bd74545936c9cc4bbf7a438",
            "value": " 1.52G/1.52G [00:19&lt;00:00, 74.8MB/s]"
          }
        },
        "b137299d575c45a195e27a030b3e0c48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9fc766bb38842acb6610055e53c0aad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb05f1d439c4b07ae5984a8f85bb6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bf34e95ca334295a3ee5063f49dc56b",
            "placeholder": "​",
            "style": "IPY_MODEL_06d276641e77412cbc372d27142e1f55",
            "value": " 124/124 [00:00&lt;00:00, 8.39kB/s]"
          }
        },
        "bdc609ea96de493899368ee46a102e66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef84d2ca11042ceaa7b08bcefb5e838": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2d24b5281004f7ca9775ac59892a264": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3ea7d7d619f4754946c58d9955d6fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c52014e636644a8bbf36af7a0e675cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e3509c630af4e1d93537834766f78d2",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9725d1c35c8c479a9ce5c049f88ffe80",
            "value": 665
          }
        },
        "c7228a0ed3c54b1fb7b38a7fe781d142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f18c5e292e4aa7a51140fcddbf62a2",
            "placeholder": "​",
            "style": "IPY_MODEL_0ef41f8bc67f46b998f2e86b30a721b8",
            "value": "generation_config.json: 100%"
          }
        },
        "c82a7f27161d4e6fb8d04414dd241466": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd384d195df64b9cb6d34e29fd85d66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2510b15e4d64aff92270b0a9daec0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6db2b44f7674bb09ad100c4464a8776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9b81007480c4318ae74291e48fc3a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c54fc0852ce44be83231bb7ae861147",
            "placeholder": "​",
            "style": "IPY_MODEL_754d6264dc654d5086ae8136f4fae5df",
            "value": "config.json: 100%"
          }
        },
        "e6639aa8a55b4b77994361650a381a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edacc9fa049a40f590cc65d4cff9d21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7228a0ed3c54b1fb7b38a7fe781d142",
              "IPY_MODEL_555875eb8c0d43d7992017c3e58870e8",
              "IPY_MODEL_1bd31081752c4131bae2de20ec7fa631"
            ],
            "layout": "IPY_MODEL_b9fc766bb38842acb6610055e53c0aad"
          }
        },
        "f56504e73df94cc8a2adefda81cc6f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8998c0820454e6b8029a22d97b4dced": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fac80442e679418a8a8ad8040ae17419": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fafa39a47cfc48f1b20d02ea8a4d47dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc0585a1666d4b0a8f5c6c0fca74d18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e590edaaf634a869031e4c0d4f25599",
            "placeholder": "​",
            "style": "IPY_MODEL_bef84d2ca11042ceaa7b08bcefb5e838",
            "value": " 548M/548M [00:02&lt;00:00, 296MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
