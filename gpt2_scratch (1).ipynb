{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sympy==1.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qnJ1qJKfOvTs",
        "outputId": "43c79474-a98e-4570-8f68-389a7d05806b"
      },
      "id": "qnJ1qJKfOvTs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy==1.12\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy==1.12) (1.3.0)\n",
            "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.9.0+cu126 requires sympy>=1.13.3, but you have sympy 1.12 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmCucnszfgEc",
        "outputId": "ae7a4353-62e5-4f29-a995-3b75b421a2d6"
      },
      "id": "fmCucnszfgEc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa84aaa",
      "metadata": {
        "id": "1fa84aaa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a96b806c",
      "metadata": {
        "id": "a96b806c"
      },
      "outputs": [],
      "source": [
        "#configuration for GPT model having 124 million parameters\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 256, #1024\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae719821",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ae719821",
        "outputId": "1f9471bc-31b1-48c0-c228-87ee5f641445"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntext\\ntoken id\\ntoken embedding\\nposition embedding\\ninput embedding\\ndropout\\nlayer normalization\\nself-attention\\ndropout\\nresidual connection\\nlayer normalization\\nfeed forward neural network\\ndropout\\nresidual connection\\nlayer normalization\\noutput logits\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\"\"\"\n",
        "text\n",
        "token id\n",
        "token embedding\n",
        "position embedding\n",
        "input embedding\n",
        "dropout\n",
        "layer normalization\n",
        "self-attention\n",
        "dropout\n",
        "residual connection\n",
        "layer normalization\n",
        "feed forward neural network\n",
        "dropout\n",
        "residual connection\n",
        "layer normalization\n",
        "output logits\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d66e22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16d66e22",
        "outputId": "cfdfdcc6-21e5-4325-9797-1230c20db407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d46531",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00d46531",
        "outputId": "5d377304-7a3e-4a5b-a739-43149006dc77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vocab_size': 50257,\n",
              " 'context_length': 256,\n",
              " 'emb_dim': 768,\n",
              " 'n_heads': 12,\n",
              " 'n_layers': 12,\n",
              " 'drop_rate': 0.1,\n",
              " 'qkv_bias': False}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#class for multi head attention_tags\n",
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_head\"\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_q = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_k = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_v = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = torch.nn.Linear(d_out, d_out)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        key = self.W_k(x)\n",
        "        query = self.W_q(x)\n",
        "        value = self.W_v(x)\n",
        "\n",
        "        #reshaping key, query, value as each token with 12 heads and each head with 64 dimensions\n",
        "        key = key.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        query = query.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        value = value.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        #transposing to get dimensions as batch size, each head with num_tokens and each token with head_dim (b, num_heads, num_tokens, head_dim)\n",
        "        key = key.transpose(1,2)\n",
        "        query = query.transpose(1,2)\n",
        "        value = value.transpose(1,2)\n",
        "\n",
        "        #calculating attention score by multiplication of query and key transpose (num_tokens, head_dim) @ (head_dim, num_tokens) = (num_tokens, num_tokens)\n",
        "        attn_scores = query @ key.transpose(2,3)\n",
        "\n",
        "        #creating mask to make the future tokens to have -inf attention score and after softmax will become zero as probability\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores = attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        #attention score is divided by sqrt of key dimension to avoid large values and then softmax is applied to get normalize weights\n",
        "        attn_weights = torch.softmax(attn_scores / key.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        #multiplying attention weights with value to get context vector (b, num_heads, num_tokens, num_tokens) * (b, num_heads, num_tokens, head_dim) = (b, num_heads, num_tokens, head_dim)\n",
        "        context_vector = (attn_weights @ value).transpose(1,2)\n",
        "        context_vector = context_vector.contiguous().view(b, num_tokens, d_in)\n",
        "        context_vector = self.out_proj(context_vector)\n",
        "\n",
        "        return context_vector\n",
        "\n",
        "#class for transformer block\n",
        "class  TransformerBlock(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttention(d_in=cfg['emb_dim'], d_out=cfg['emb_dim'], context_length=cfg['context_length'],\n",
        "                                    num_heads=cfg['n_heads'], dropout=cfg['drop_rate'], qkv_bias=cfg['qkv_bias'])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 =  LayerNorm(cfg['emb_dim'])\n",
        "        self.norm2 =  LayerNorm(cfg['emb_dim'])\n",
        "        self.drop_shortcut = torch.nn.Dropout(cfg['drop_rate'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.attn(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "        return x\n",
        "\n",
        "#class for layer normalization\n",
        "class  LayerNorm(torch.nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = torch.nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = torch.nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * x_norm + self.shift\n",
        "\n",
        "#class for GELU activaton function\n",
        "class GELU(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) *(x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "#class for feed forward neural network\n",
        "class FeedForward(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(cfg['emb_dim'], 4*cfg['emb_dim']),\n",
        "            GELU(),\n",
        "            torch.nn.Linear(4*cfg['emb_dim'], cfg['emb_dim'])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class GPTmodel(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.token_emb = torch.nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
        "        self.pos_emb = torch.nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
        "        self.drop_emb = torch.nn.Dropout(cfg['drop_rate'])\n",
        "\n",
        "        self.trf_blocks = torch.nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg['n_layers'])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
        "        self.out_head = torch.nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_length = in_idx.shape\n",
        "        token_embeds = self.token_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_length, device=in_idx.device))\n",
        "        x = token_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits #shape: (batch_size, seq_length, vocab_size)\n",
        "GPT_CONFIG_124M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99a75443",
      "metadata": {
        "id": "99a75443"
      },
      "outputs": [],
      "source": [
        "# function to convert text to token ids and vice versa\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff46831",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ff46831",
        "outputId": "089ce12e-a926-445f-ad1f-ac735939d220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[15496,     0,   314,   716]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "text1 = 'Hello! I am'\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "input_ids=text_to_token_ids(text1, tokenizer)\n",
        "print(input_ids)\n",
        "input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a13cd6",
      "metadata": {
        "id": "08a13cd6"
      },
      "outputs": [],
      "source": [
        "#generating text from the model\n",
        "def generate_text(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None: #taking top k logits and setting rest to -inf\n",
        "            top_logits, _ = torch.topk(logits, top_k, dim=-1)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        if temperature>0.0: #applying temperature scaling and sampling from the distribution\n",
        "            logits = logits/temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1) #(batch_size, 1)\n",
        "        else:\n",
        "            next_token = torch.argmax(logits, dim=-1, keepdim=True) #(batch, 1)\n",
        "\n",
        "        if next_token == eos_id: #stop generation if end of sequence token is generated\n",
        "            break\n",
        "\n",
        "        idx = torch.cat((idx, next_token), dim=1) #(batch,n_tokens+1) concatenating the new token to the existing sequence\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "621cec8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "621cec8b",
        "outputId": "60bda97e-37e2-4a60-87d1-2318d9b9ed89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[15496,     0,   314,   716, 13240, 11381,  4307,  7640, 33491, 12254,\n",
            "         26050,  8942, 44168, 35735]])\n",
            "Hello! I am Laur inhab Distrinereplacefly279 Burn issuerurnal\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "model.eval() # set the model to evaluation mode , stops acting like training, dropout works as identity\n",
        "result_tokens = generate_text(model=model, idx=input_ids, max_new_tokens=10, context_size=GPT_CONFIG_124M['context_length'])\n",
        "print(result_tokens)\n",
        "decoded_output = tokenizer.decode(result_tokens[0].tolist())\n",
        "print(decoded_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9566a479",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9566a479",
        "outputId": "983128f8-2e7e-4396-e53b-2b26d633bedc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tokenizer.eot_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d05d60",
      "metadata": {
        "id": "15d05d60"
      },
      "outputs": [],
      "source": [
        "#function to generate and print text from the model\n",
        "def generate_and_print(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_tokens = generate_text(model, encoded, max_new_tokens=50, context_size=context_size, temperature=0.8, top_k=50, eos_id=tokenizer.eot_token)\n",
        "    decoded_text = token_ids_to_text(generated_tokens, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\",\" \"))\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca2d0f5b",
      "metadata": {
        "id": "ca2d0f5b"
      },
      "outputs": [],
      "source": [
        "#will create now dataset and dataloader using bpe_tokenizer and the verdict text file\n",
        "#we will use this class in dataloader to create batches of data\n",
        "class GPTDatasetv1:\n",
        "    def __init__(self, text, tokenizer, max_len, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "        token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0, len(token_ids)-max_len, stride):\n",
        "            input_id = token_ids[i:i+max_len]\n",
        "            target_id = token_ids[i+1:i+max_len+1]\n",
        "            self.input_ids.append(torch.tensor(input_id))\n",
        "            self.target_ids.append(torch.tensor(target_id))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "#dataloader function to create batches of data\n",
        "def create_dataloaderv1(text, batch_size=4, max_len=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset1 = GPTDatasetv1(text, tokenizer, max_len, stride)\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d350cdcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d350cdcc",
        "outputId": "92febb67-7df5-4162-9f40-4d2cd972d966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total tokens: 5145, total characters: 20479\n"
          ]
        }
      ],
      "source": [
        "#Dataset is now stored in variable content\n",
        "# with open(\"/content/drive/MyDrive/Dataset/the-verdict.txt\") as file:\n",
        "with open(\"/content/drive/MyDrive/Khanakh/Dataset/the-verdict.txt\") as file:\n",
        "    content = file.read()\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "total_tokens = len(tokenizer.encode(content))\n",
        "total_characters = len(content)\n",
        "print(f\"total tokens: {total_tokens}, total characters: {total_characters}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ecd329",
      "metadata": {
        "id": "b7ecd329"
      },
      "outputs": [],
      "source": [
        "#training and validation dataloaders\n",
        "train_ratio = 0.9\n",
        "tokens = tokenizer.encode(content)\n",
        "split = int(train_ratio * len(tokens))\n",
        "\n",
        "train_tokens = tokens[:split]\n",
        "val_tokens = tokens[split:]\n",
        "\n",
        "train_data = tokenizer.decode(train_tokens)\n",
        "val_data = tokenizer.decode(val_tokens)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataloader = create_dataloaderv1(text=train_data, batch_size=2, max_len=GPT_CONFIG_124M['context_length'],\n",
        "                                    stride=GPT_CONFIG_124M['context_length'], shuffle=True, drop_last=True, num_workers=0)\n",
        "\n",
        "val_dataloader = create_dataloaderv1(text=val_data, batch_size=2, max_len=GPT_CONFIG_124M['context_length'],\n",
        "                                    stride=GPT_CONFIG_124M['context_length'], shuffle=False, drop_last=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204e78f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "204e78f3",
        "outputId": "00beccb8-a485-4ac0-8392-8699f96479b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "for x,y in train_dataloader:\n",
        "    print(x.shape, y.shape)\n",
        "#this shows us total lines as total number of batches with each batch having 2 samples (input and target) of (2, 1024) shape which means batch size (sequences) is 2 and each sample has 1024 tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1de9fb8",
      "metadata": {
        "id": "c1de9fb8"
      },
      "outputs": [],
      "source": [
        "#function to calculate loss using cross entropy loss per batch\n",
        "def compute_loss(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "#calculate average loss for specified number of batches from dataloader\n",
        "def calc_loss_loader(dataloader, model, device, num_batches=None):\n",
        "    total_loss = 0\n",
        "    if len(dataloader) == 0:\n",
        "        return float('nan')\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(dataloader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(dataloader))\n",
        "        for i, (input_batch, target_batch) in enumerate(dataloader):\n",
        "            if i < num_batches:\n",
        "                loss = compute_loss(input_batch, target_batch, model, device)\n",
        "                total_loss += loss.item()\n",
        "            else:\n",
        "                break\n",
        "        avg_loss = total_loss / num_batches\n",
        "    return avg_loss\n",
        "\n",
        "#function to calculate training and validation loss at regular intervals(batches/eval_iter)\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68fdd1c9",
      "metadata": {
        "id": "68fdd1c9"
      },
      "outputs": [],
      "source": [
        "#training loop for llm model\n",
        "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
        "    #initialize list to track training and validation loss and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [],[],[]\n",
        "    tokens_seen, global_step = 0, 0\n",
        "\n",
        "    #training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train() #set the model to training mode\n",
        "        for (input_batch, target_batch) in train_loader:\n",
        "            optimizer.zero_grad() #clear previous gradients\n",
        "            loss = compute_loss(input_batch, target_batch, model, device)\n",
        "            loss.backward() #backpropagation (calculate loss backwards)\n",
        "            optimizer.step() #update model parameters\n",
        "            tokens_seen += input_batch.numel() #number of tokens seen so far\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Epoch {epoch+1}, step {global_step}: train_loss = {train_loss:.3f}, val_loss = {val_loss:.3f}, tokens_seen = {tokens_seen}\")\n",
        "\n",
        "        generate_and_print(model, tokenizer, device, start_context)\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c1e23d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38c1e23d",
        "outputId": "5d6829a6-e367-4a09-da15-29e91e18f073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, step 2: train_loss = 8.618, val_loss = 8.164, tokens_seen = 1024\n",
            "Epoch 1, step 4: train_loss = 7.466, val_loss = 7.590, tokens_seen = 2048\n",
            "Epoch 1, step 6: train_loss = 8.427, val_loss = 8.799, tokens_seen = 3072\n",
            "Epoch 1, step 8: train_loss = 8.495, val_loss = 8.532, tokens_seen = 4096\n",
            "Every effort moves you fact not eyes would in..I it her- that And ofis.. in him he. a in not who notthe would St that it been. G G--.roud? he her\".I in out- he It painting\n",
            "Epoch 2, step 10: train_loss = 7.379, val_loss = 8.328, tokens_seen = 5120\n",
            "Epoch 2, step 12: train_loss = 7.697, val_loss = 8.376, tokens_seen = 6144\n",
            "Epoch 2, step 14: train_loss = 6.972, val_loss = 8.505, tokens_seen = 7168\n",
            "Epoch 2, step 16: train_loss = 6.948, val_loss = 8.401, tokens_seen = 8192\n",
            "Epoch 2, step 18: train_loss = 6.676, val_loss = 8.397, tokens_seen = 9216\n",
            "Every effort moves you my my\":. was he. it.. it.--burn to the as had. a. to I of with was't all-- my, it was to work I I had it it. about\" I my no a a you\n",
            "Epoch 3, step 20: train_loss = 6.829, val_loss = 8.511, tokens_seen = 10240\n",
            "Epoch 3, step 22: train_loss = 6.807, val_loss = 8.586, tokens_seen = 11264\n",
            "Epoch 3, step 24: train_loss = 6.388, val_loss = 8.484, tokens_seen = 12288\n",
            "Epoch 3, step 26: train_loss = 6.383, val_loss = 8.366, tokens_seen = 13312\n",
            "Every effort moves you, their the--,\"   roud had a, with , to Mrs the of, St the my he it . the, a and. under a and of   just?.,  the by a of,, he\n",
            "Epoch 4, step 28: train_loss = 6.555, val_loss = 8.388, tokens_seen = 14336\n",
            "Epoch 4, step 30: train_loss = 6.054, val_loss = 8.412, tokens_seen = 15360\n",
            "Epoch 4, step 32: train_loss = 6.377, val_loss = 8.237, tokens_seen = 16384\n",
            "Epoch 4, step 34: train_loss = 6.301, val_loss = 8.113, tokens_seen = 17408\n",
            "Epoch 4, step 36: train_loss = 6.055, val_loss = 8.040, tokens_seen = 18432\n",
            "Every effort moves you theI that and and.-- heI you I his me, how, he me to--'t't.., you to-- him was was me and to\"\" her one and't to.\" the and,I was he: was\n",
            "Epoch 5, step 38: train_loss = 6.361, val_loss = 8.009, tokens_seen = 19456\n",
            "Epoch 5, step 40: train_loss = 6.266, val_loss = 8.050, tokens_seen = 20480\n",
            "Epoch 5, step 42: train_loss = 6.422, val_loss = 8.028, tokens_seen = 21504\n",
            "Epoch 5, step 44: train_loss = 6.095, val_loss = 7.962, tokens_seen = 22528\n",
            "Every effort moves you-- with with the. have. of so it,\" his,,., and, he a and the, he,\"., hadis the G a a, in a of the.  , my in what, own, my of\n",
            "Epoch 6, step 46: train_loss = 6.099, val_loss = 7.948, tokens_seen = 23552\n",
            "Epoch 6, step 48: train_loss = 6.033, val_loss = 8.071, tokens_seen = 24576\n",
            "Epoch 6, step 50: train_loss = 6.013, val_loss = 8.125, tokens_seen = 25600\n",
            "Epoch 6, step 52: train_loss = 5.954, val_loss = 8.061, tokens_seen = 26624\n",
            "Epoch 6, step 54: train_loss = 6.017, val_loss = 7.919, tokens_seen = 27648\n",
            "Every effort moves you when he up her was he he the. in.  .. (. the the his\" the, him in his by me,, to the  I his was.\" with I the when.\"-- the   I his on not\n",
            "Epoch 7, step 56: train_loss = 6.106, val_loss = 7.887, tokens_seen = 28672\n",
            "Epoch 7, step 58: train_loss = 5.915, val_loss = 7.859, tokens_seen = 29696\n",
            "Epoch 7, step 60: train_loss = 5.849, val_loss = 7.760, tokens_seen = 30720\n",
            "Epoch 7, step 62: train_loss = 5.828, val_loss = 7.665, tokens_seen = 31744\n",
            "Every effort moves you on to  after the. St theis. _ , one to his. to,'s. the\". not him, him to one.  foundations--. I it to-- to and my to to, you.. But till\n",
            "Epoch 8, step 64: train_loss = 5.939, val_loss = 7.625, tokens_seen = 32768\n",
            "Epoch 8, step 66: train_loss = 5.723, val_loss = 7.678, tokens_seen = 33792\n",
            "Epoch 8, step 68: train_loss = 5.719, val_loss = 7.711, tokens_seen = 34816\n",
            "Epoch 8, step 70: train_loss = 5.864, val_loss = 7.776, tokens_seen = 35840\n",
            "Epoch 8, step 72: train_loss = 5.706, val_loss = 7.754, tokens_seen = 36864\n",
            "Every effort moves you her his not \"\" point,.I had one had---- a   wife he had a I of of,\" the And---.\"  is. G-- hisI the  first; a \" art up as me\n",
            "Epoch 9, step 74: train_loss = 5.886, val_loss = 7.733, tokens_seen = 37888\n",
            "Epoch 9, step 76: train_loss = 5.838, val_loss = 7.721, tokens_seen = 38912\n",
            "Epoch 9, step 78: train_loss = 5.711, val_loss = 7.671, tokens_seen = 39936\n",
            "Epoch 9, step 80: train_loss = 5.709, val_loss = 7.595, tokens_seen = 40960\n",
            "Every effort moves you. \"  ,--'s Mrs,---- to one him was Mrs,-- had in----,-- had in_, had a. . be own it it. was she my-- I, was a . show,.\"\n",
            "Epoch 10, step 82: train_loss = 5.820, val_loss = 7.592, tokens_seen = 41984\n",
            "Epoch 10, step 84: train_loss = 5.525, val_loss = 7.594, tokens_seen = 43008\n",
            "Epoch 10, step 86: train_loss = 5.784, val_loss = 7.578, tokens_seen = 44032\n",
            "Epoch 10, step 88: train_loss = 5.860, val_loss = 7.576, tokens_seen = 45056\n",
            "Epoch 10, step 90: train_loss = 5.593, val_loss = 7.516, tokens_seen = 46080\n",
            "Every effort moves you been  \" up of.  is a I of in the    is a Th\"  Well.The .   wall one.\"--  I a  tricks, to theI-- . \n"
          ]
        }
      ],
      "source": [
        "#train the model\n",
        "torch.manual_seed(123)\n",
        "model = GPTmodel(GPT_CONFIG_124M).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.004, weight_decay=0.01)\n",
        "num_epochs = 10\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model(model=model, train_loader=train_dataloader, val_loader=val_dataloader, optimizer=optimizer,\n",
        "                                                    device=device, num_epochs=num_epochs, eval_freq=4, eval_iter=4,\n",
        "                                                    start_context=\"Every effort moves you\", tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df940976",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df940976",
        "outputId": "0a2a94fa-427f-49b6-85ce-11c7024ae05e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you the his the,, me, theYes the  wife, of have. \" it of.   \" I to the    little, on,'s you.   Oh the,. Yes he- the\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "generate_and_print(model, tokenizer, device, start_context='Every effort moves you')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving and loading model weights"
      ],
      "metadata": {
        "id": "oPAkIgvZXSS8"
      },
      "id": "oPAkIgvZXSS8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87ea7fc",
      "metadata": {
        "id": "e87ea7fc"
      },
      "outputs": [],
      "source": [
        "#saves the model weight to given path\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "torch.save(model.state_dict(), 'gpt2_rand_weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b920df2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b920df2",
        "outputId": "59f28431-1dda-4def-91d1-b93b86b86de8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#load the model weights into new gptmodel model instance\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load('gpt2_rand_weights.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a65a4b1f",
      "metadata": {
        "id": "a65a4b1f"
      },
      "outputs": [],
      "source": [
        "#to save both model weights and optimizer parameters\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2023c784",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2023c784",
        "outputId": "e76028ae-cdee-47ac-d19d-9e5ddb16e24d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTmodel(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#loads both model weights and optimizer parameter for each weight\n",
        "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c284f8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c284f8d",
        "outputId": "eaa0695a-f9fe-4b1e-f50f-5af4d0610b22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162419712"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "total_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Pretrained weights"
      ],
      "metadata": {
        "id": "u9HfFvniWisZ"
      },
      "id": "u9HfFvniWisZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "590e4666",
      "metadata": {
        "id": "590e4666"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46536875",
      "metadata": {
        "id": "46536875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "8e8e57657d01444fb53099dd1ad9e91f",
            "06c60e5ddd2a44749be0cf496728bd41",
            "c52014e636644a8bbf36af7a0e675cfd",
            "6602fc5721c445a3b93a9beaae2be4a1",
            "51306772f89d42ccbf94a28c659a98b4",
            "6cc8d444b7414eb1b091f93bb39a66dd",
            "a27d25b2c08845f18cc3eab0aa1c0675",
            "1e3509c630af4e1d93537834766f78d2",
            "9725d1c35c8c479a9ce5c049f88ffe80",
            "1ddfab07551c44df87e1f8faddacdeee",
            "e6639aa8a55b4b77994361650a381a9b",
            "3a6f8f46126e4cb78aaedcd70e74a200",
            "a1654069382b4c04ad5ab480eaaaba51",
            "4cd195d22eed491f98bdc63b6d851a4f",
            "fc0585a1666d4b0a8f5c6c0fca74d18b",
            "4dc468f4667d460c82dd17f15c0f0857",
            "5761439544f44d3984fbbc6e9573c9e9",
            "d6db2b44f7674bb09ad100c4464a8776",
            "1e7d69871aeb44a284e28ff08de32986",
            "f8998c0820454e6b8029a22d97b4dced",
            "5e590edaaf634a869031e4c0d4f25599",
            "bef84d2ca11042ceaa7b08bcefb5e838",
            "9e17e99481464471b0d5622b2860b2d4",
            "a6aca18f95f6437fb83e9913be450adf",
            "8d536187aa8d4bc0b54a78bc489c2c90",
            "bcb05f1d439c4b07ae5984a8f85bb6cf",
            "90e3c047db144ae7bca91e7b971ee2c0",
            "c2d24b5281004f7ca9775ac59892a264",
            "f56504e73df94cc8a2adefda81cc6f24",
            "c3ea7d7d619f4754946c58d9955d6fd6",
            "cd384d195df64b9cb6d34e29fd85d66b",
            "4bf34e95ca334295a3ee5063f49dc56b",
            "06d276641e77412cbc372d27142e1f55"
          ]
        },
        "outputId": "721926cd-396b-43ef-acf8-6c56d6a31cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e8e57657d01444fb53099dd1ad9e91f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a6f8f46126e4cb78aaedcd70e74a200"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e17e99481464471b0d5622b2860b2d4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#load pretrained gpt2 model and tokenizer from huggingface transformers library\n",
        "model_name = 'gpt2'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model_new = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3def69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce3def69",
        "outputId": "84548c9e-118e-4241-9973-64acac28d84a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformer.wte.weight  torch.Size([50257, 768])\n",
            "transformer.wpe.weight  torch.Size([1024, 768])\n",
            "transformer.h.0.ln_1.weight  torch.Size([768])\n",
            "transformer.h.0.ln_1.bias  torch.Size([768])\n",
            "transformer.h.0.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.0.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.0.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.0.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.0.ln_2.weight  torch.Size([768])\n",
            "transformer.h.0.ln_2.bias  torch.Size([768])\n",
            "transformer.h.0.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.0.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.0.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.0.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.1.ln_1.weight  torch.Size([768])\n",
            "transformer.h.1.ln_1.bias  torch.Size([768])\n",
            "transformer.h.1.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.1.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.1.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.1.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.1.ln_2.weight  torch.Size([768])\n",
            "transformer.h.1.ln_2.bias  torch.Size([768])\n",
            "transformer.h.1.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.1.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.1.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.1.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.2.ln_1.weight  torch.Size([768])\n",
            "transformer.h.2.ln_1.bias  torch.Size([768])\n",
            "transformer.h.2.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.2.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.2.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.2.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.2.ln_2.weight  torch.Size([768])\n",
            "transformer.h.2.ln_2.bias  torch.Size([768])\n",
            "transformer.h.2.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.2.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.2.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.2.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.3.ln_1.weight  torch.Size([768])\n",
            "transformer.h.3.ln_1.bias  torch.Size([768])\n",
            "transformer.h.3.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.3.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.3.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.3.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.3.ln_2.weight  torch.Size([768])\n",
            "transformer.h.3.ln_2.bias  torch.Size([768])\n",
            "transformer.h.3.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.3.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.3.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.3.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.4.ln_1.weight  torch.Size([768])\n",
            "transformer.h.4.ln_1.bias  torch.Size([768])\n",
            "transformer.h.4.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.4.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.4.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.4.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.4.ln_2.weight  torch.Size([768])\n",
            "transformer.h.4.ln_2.bias  torch.Size([768])\n",
            "transformer.h.4.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.4.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.4.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.4.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.5.ln_1.weight  torch.Size([768])\n",
            "transformer.h.5.ln_1.bias  torch.Size([768])\n",
            "transformer.h.5.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.5.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.5.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.5.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.5.ln_2.weight  torch.Size([768])\n",
            "transformer.h.5.ln_2.bias  torch.Size([768])\n",
            "transformer.h.5.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.5.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.5.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.5.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.6.ln_1.weight  torch.Size([768])\n",
            "transformer.h.6.ln_1.bias  torch.Size([768])\n",
            "transformer.h.6.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.6.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.6.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.6.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.6.ln_2.weight  torch.Size([768])\n",
            "transformer.h.6.ln_2.bias  torch.Size([768])\n",
            "transformer.h.6.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.6.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.6.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.6.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.7.ln_1.weight  torch.Size([768])\n",
            "transformer.h.7.ln_1.bias  torch.Size([768])\n",
            "transformer.h.7.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.7.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.7.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.7.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.7.ln_2.weight  torch.Size([768])\n",
            "transformer.h.7.ln_2.bias  torch.Size([768])\n",
            "transformer.h.7.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.7.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.7.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.7.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.8.ln_1.weight  torch.Size([768])\n",
            "transformer.h.8.ln_1.bias  torch.Size([768])\n",
            "transformer.h.8.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.8.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.8.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.8.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.8.ln_2.weight  torch.Size([768])\n",
            "transformer.h.8.ln_2.bias  torch.Size([768])\n",
            "transformer.h.8.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.8.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.8.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.8.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.9.ln_1.weight  torch.Size([768])\n",
            "transformer.h.9.ln_1.bias  torch.Size([768])\n",
            "transformer.h.9.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.9.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.9.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.9.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.9.ln_2.weight  torch.Size([768])\n",
            "transformer.h.9.ln_2.bias  torch.Size([768])\n",
            "transformer.h.9.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.9.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.9.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.9.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.10.ln_1.weight  torch.Size([768])\n",
            "transformer.h.10.ln_1.bias  torch.Size([768])\n",
            "transformer.h.10.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.10.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.10.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.10.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.10.ln_2.weight  torch.Size([768])\n",
            "transformer.h.10.ln_2.bias  torch.Size([768])\n",
            "transformer.h.10.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.10.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.10.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.10.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.11.ln_1.weight  torch.Size([768])\n",
            "transformer.h.11.ln_1.bias  torch.Size([768])\n",
            "transformer.h.11.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.11.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.11.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.11.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.11.ln_2.weight  torch.Size([768])\n",
            "transformer.h.11.ln_2.bias  torch.Size([768])\n",
            "transformer.h.11.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.11.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.11.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.11.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.ln_f.weight  torch.Size([768])\n",
            "transformer.ln_f.bias  torch.Size([768])\n",
            "lm_head.weight  torch.Size([50257, 768])\n"
          ]
        }
      ],
      "source": [
        "param = model_new.state_dict()\n",
        "for key in param:\n",
        "  print(key, \"\", param[key].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5cd451",
      "metadata": {
        "id": "4c5cd451"
      },
      "outputs": [],
      "source": [
        "#configuration for GPT model having 124 million parameters\n",
        "NEW_CONFIG = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.2,\n",
        "    \"qkv_bias\": True\n",
        "}\n",
        "gpt = GPTmodel(NEW_CONFIG)\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_new.transformer.h[0].mlp.c_proj.bias[:5]\n",
        "len(model_new.transformer.h)\n",
        "model_new.transformer.h[0].attn.c_attn.weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGYHFyv_oaUk",
        "outputId": "097f6633-8508-4dc0-c296-e667213a68ea"
      },
      "id": "OGYHFyv_oaUk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768, 2304])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_weights_into_gpt(gpt, model_new):\n",
        "  with torch.no_grad():\n",
        "    gpt.token_emb.weight.copy_(model_new.transformer.wte.weight)\n",
        "    gpt.pos_emb.weight.copy_(model_new.transformer.wpe.weight)\n",
        "\n",
        "    for i in range(len(model_new.transformer.h)):\n",
        "\n",
        "      qkv_w = model_new.transformer.h[i].attn.c_attn.weight\n",
        "      q_w, k_w, v_w = torch.split(qkv_w,gpt.trf_blocks[i].attn.W_q.weight.shape[0],dim=-1)\n",
        "      gpt.trf_blocks[i].attn.W_q.weight.copy_(q_w.T)\n",
        "      gpt.trf_blocks[i].attn.W_k.weight.copy_(k_w.T)\n",
        "      gpt.trf_blocks[i].attn.W_v.weight.copy_(v_w.T)\n",
        "\n",
        "      qkv_b = model_new.transformer.h[i].attn.c_attn.bias\n",
        "      q_b, k_b, v_b = torch.split(qkv_b,gpt.trf_blocks[i].attn.W_q.bias.shape[0],dim=-1)\n",
        "      gpt.trf_blocks[i].attn.W_q.bias.copy_(q_b)\n",
        "      gpt.trf_blocks[i].attn.W_k.bias.copy_(k_b)\n",
        "      gpt.trf_blocks[i].attn.W_v.bias.copy_(v_b)\n",
        "\n",
        "      gpt.trf_blocks[i].attn.out_proj.weight.copy_(model_new.transformer.h[i].attn.c_proj.weight.T)\n",
        "      gpt.trf_blocks[i].attn.out_proj.bias.copy_(model_new.transformer.h[i].attn.c_proj.bias)\n",
        "\n",
        "      gpt.trf_blocks[i].ff.layers[0].weight.copy_(model_new.transformer.h[i].mlp.c_fc.weight.T)\n",
        "      gpt.trf_blocks[i].ff.layers[0].bias.copy_(model_new.transformer.h[i].mlp.c_fc.bias)\n",
        "      gpt.trf_blocks[i].ff.layers[2].weight.copy_(model_new.transformer.h[i].mlp.c_proj.weight.T)\n",
        "      gpt.trf_blocks[i].ff.layers[2].bias.copy_(model_new.transformer.h[i].mlp.c_proj.bias)\n",
        "\n",
        "      gpt.trf_blocks[i].norm1.scale.copy_(model_new.transformer.h[i].ln_1.weight)\n",
        "      gpt.trf_blocks[i].norm1.shift.copy_(model_new.transformer.h[i].ln_1.bias)\n",
        "      gpt.trf_blocks[i].norm2.scale.copy_(model_new.transformer.h[i].ln_2.weight)\n",
        "      gpt.trf_blocks[i].norm2.shift.copy_(model_new.transformer.h[i].ln_2.bias)\n",
        "\n",
        "    gpt.final_norm.scale.copy_(model_new.transformer.ln_f.weight)\n",
        "    gpt.final_norm.shift.copy_(model_new.transformer.ln_f.bias)\n",
        "    gpt.out_head.weight.copy_(model_new.transformer.wte.weight)\n"
      ],
      "metadata": {
        "id": "-OC5FNVjfQCM"
      },
      "id": "-OC5FNVjfQCM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt,model_new)\n",
        "gpt.to(device)"
      ],
      "metadata": {
        "id": "kFvsMf8Qvpmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94542317-afe8-4568-9fe8-15399446d6a8"
      },
      "id": "kFvsMf8Qvpmm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTmodel(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "pLmL5q3mH58d"
      },
      "id": "pLmL5q3mH58d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "generated_tokens = generate_text(gpt, text_to_token_ids(\"Every effort moves you\", tokenizer).to(device), max_new_tokens=50,\n",
        "                                context_size=NEW_CONFIG[\"context_length\"], temperature=0.8, top_k=50, eos_id=tokenizer.eot_token)\n",
        "\n",
        "output = token_ids_to_text(generated_tokens, tokenizer)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "WsnBSlMsvpj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80465502-27ed-4666-b501-b9e55964ffbb"
      },
      "id": "WsnBSlMsvpj2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you as far as the eye can see. (That's because you're not going to be able to see it all.) I think the most interesting thing about this is that there's an easy way to avoid it. You can get that with a couple\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Finetuning using pretrained weights"
      ],
      "metadata": {
        "id": "uK2NOJvwWU4B"
      },
      "id": "uK2NOJvwWU4B"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#finetuning for classification dataset (sms spam or not)\n",
        "# df1 = pd.read_csv(\"/content/drive/MyDrive/Dataset/email+sms+spam+collection/SMSSpamCollection\",sep=\"\\t\", names=[\"Label\",\"Text\"])\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Khanakh/Dataset/email+sms+spam+collection/SMSSpamCollection\",sep=\"\\t\", names=[\"Label\",\"Text\"])\n",
        "df1"
      ],
      "metadata": {
        "id": "DMtYmOIqfP1v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "collapsed": true,
        "outputId": "c2b93c77-771e-42a8-8002-b5d302893cf9"
      },
      "id": "DMtYmOIqfP1v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-616daa04-0274-4b47-9584-a9eb47bfc97f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-616daa04-0274-4b47-9584-a9eb47bfc97f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-616daa04-0274-4b47-9584-a9eb47bfc97f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-616daa04-0274-4b47-9584-a9eb47bfc97f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_b75f0685-4755-4aa5-88c8-5fbc28cdf34d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b75f0685-4755-4aa5-88c8-5fbc28cdf34d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1[\"Label\"].unique())\n",
        "print(df1[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Rybesm8uLOaM",
        "outputId": "87fbec70-1c25-47ef-9129-9df745146e10"
      },
      "id": "Rybesm8uLOaM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ham' 'spam']\n",
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df2 = pd.read_csv(\"/content/drive/MyDrive/Dataset/email+sms+spam+collection/SMS_Spam_dataset.csv\")\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Khanakh/Dataset/email+sms+spam+collection/SMS_Spam_dataset.csv\")\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "collapsed": true,
        "id": "KiJf6BiTLOXb",
        "outputId": "392fb7bb-8fe9-4120-a817-663994751ba2"
      },
      "id": "KiJf6BiTLOXb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target                                               text\n",
              "0       spam  Congratulations! You've been selected for a lu...\n",
              "1       spam  URGENT: Your account has been compromised. Cli...\n",
              "2       spam  You've won a free iPhone! Claim your prize by ...\n",
              "3       spam  Act now and receive a 50% discount on all purc...\n",
              "4       spam  Important notice: Your subscription will expir...\n",
              "...      ...                                                ...\n",
              "10956   spam  Hey little one! Exciting news! Mama and baby a...\n",
              "10957   spam  Amazing DATA deals on your Pulse Plan today! D...\n",
              "10958   spam  Special offer just for you! Get 1GB @15 bob va...\n",
              "10959   spam  NEW ARRIVAL - JUNE 23RD  Dresses @ 300; Kondel...\n",
              "10960   spam  Coureen, did you know that saving on Timiza in...\n",
              "\n",
              "[10961 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-838ae616-a311-49cc-829a-d68b920f0366\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spam</td>\n",
              "      <td>Congratulations! You've been selected for a lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>URGENT: Your account has been compromised. Cli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>You've won a free iPhone! Claim your prize by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spam</td>\n",
              "      <td>Act now and receive a 50% discount on all purc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam</td>\n",
              "      <td>Important notice: Your subscription will expir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10956</th>\n",
              "      <td>spam</td>\n",
              "      <td>Hey little one! Exciting news! Mama and baby a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10957</th>\n",
              "      <td>spam</td>\n",
              "      <td>Amazing DATA deals on your Pulse Plan today! D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10958</th>\n",
              "      <td>spam</td>\n",
              "      <td>Special offer just for you! Get 1GB @15 bob va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10959</th>\n",
              "      <td>spam</td>\n",
              "      <td>NEW ARRIVAL - JUNE 23RD  Dresses @ 300; Kondel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10960</th>\n",
              "      <td>spam</td>\n",
              "      <td>Coureen, did you know that saving on Timiza in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10961 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-838ae616-a311-49cc-829a-d68b920f0366')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-838ae616-a311-49cc-829a-d68b920f0366 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-838ae616-a311-49cc-829a-d68b920f0366');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_8be1119c-34d2-44f1-8e46-5180a82a47a5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8be1119c-34d2-44f1-8e46-5180a82a47a5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 10961,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ham\",\n          \"spam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10286,\n        \"samples\": [\n          \"SERIOUSLY. TELL HER THOSE EXACT WORDS RIGHT NOW.\",\n          \"Dhoni have luck to win some big title.so we will win:)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.rename(columns={'target':'Label', 'text':'Text'}, inplace=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5_5KuNAALONB"
      },
      "id": "5_5KuNAALONB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "collapsed": true,
        "id": "q8qpWBqhLOKc",
        "outputId": "f28831cc-caae-4912-cccf-e614c792cd4c"
      },
      "id": "q8qpWBqhLOKc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "ham     8555\n",
              "spam    2406\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>8555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>2406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df1,df2], ignore_index=True, axis=0)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ARxvSgwYLOHk"
      },
      "id": "ARxvSgwYLOHk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.duplicated()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "collapsed": true,
        "id": "SjG5RXnzLOE1",
        "outputId": "3c1d5c52-9e25-455a-ab7a-638508bb2ca9"
      },
      "id": "SjG5RXnzLOE1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Label                                               Text\n",
              "103     ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "154     ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "207     ham  As I entered my cabin my PA said, '' Happy B'd...\n",
              "223     ham                             Sorry, I'll call later\n",
              "326     ham                   No calls..messages..missed calls\n",
              "...     ...                                                ...\n",
              "16418  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
              "16421   ham  Pity, * was in mood for that. So...any other s...\n",
              "16422   ham  The guy did some bitching but I acted like i'd...\n",
              "16423   ham                         Rofl. Its true to its name\n",
              "16430   ham  AFE Model Casting Call  Model Casting Call\\nTh...\n",
              "\n",
              "[5690 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5316f521-1994-47fe-b3d2-c39a55085b9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>ham</td>\n",
              "      <td>As I entered my cabin my PA said, '' Happy B'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>ham</td>\n",
              "      <td>No calls..messages..missed calls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16418</th>\n",
              "      <td>spam</td>\n",
              "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16421</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16422</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16423</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16430</th>\n",
              "      <td>ham</td>\n",
              "      <td>AFE Model Casting Call  Model Casting Call\\nTh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5690 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5316f521-1994-47fe-b3d2-c39a55085b9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5316f521-1994-47fe-b3d2-c39a55085b9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5316f521-1994-47fe-b3d2-c39a55085b9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[df\",\n  \"rows\": 5690,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4958,\n        \"samples\": [\n          \"Just do what ever is easier for you\",\n          \"I meant middle left or right?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(ignore_index=True, inplace=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lXiZwEvWq94S"
      },
      "id": "lXiZwEvWq94S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.duplicated(subset='Text', keep=False)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "a-1GjTocq9yT",
        "outputId": "589ca02e-6728-473e-c6cc-1ab5618271e6"
      },
      "id": "a-1GjTocq9yT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Label                                               Text\n",
              "10810  spam  Your Account Was Accessed From a New Device We...\n",
              "10811   ham  Your Account Was Accessed From a New Device We..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffe62be4-28e5-4384-8ce3-7700353aebf6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10810</th>\n",
              "      <td>spam</td>\n",
              "      <td>Your Account Was Accessed From a New Device We...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10811</th>\n",
              "      <td>ham</td>\n",
              "      <td>Your Account Was Accessed From a New Device We...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffe62be4-28e5-4384-8ce3-7700353aebf6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ffe62be4-28e5-4384-8ce3-7700353aebf6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ffe62be4-28e5-4384-8ce3-7700353aebf6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ham\",\n          \"spam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Your Account Was Accessed From a New Device We noticed a new login\\nHello ondiekijohn254@gmail.com, we noticed an unusual login from a device or location you don't usually use.\\nWas this you?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset='Text', ignore_index=True, inplace=True)"
      ],
      "metadata": {
        "id": "kOu2-OcYq9vh",
        "collapsed": true
      },
      "id": "kOu2-OcYq9vh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "omR5lnCMq9sl",
        "outputId": "54a0339b-ec52-4ef4-fdc8-a3c60f5c707b",
        "collapsed": true
      },
      "id": "omR5lnCMq9sl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "ham     8341\n",
              "spam    2501\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>8341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>2501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#keep equal number of data for both labels\n",
        "def create_balanced_dataset(df):\n",
        "  num_spam = df[df['Label']=='spam'].shape[0]\n",
        "  ham_subset = df[df['Label']=='ham'].sample(num_spam, random_state=123)\n",
        "  balanced_df = pd.concat([ham_subset, df[df['Label']=='spam']])\n",
        "\n",
        "  return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "balanced_df['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "RjeFMGv2q9pb",
        "outputId": "efdecb0c-750c-4d70-d7cb-062994aa2985",
        "collapsed": true
      },
      "id": "RjeFMGv2q9pb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "ham     2501\n",
              "spam    2501\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>2501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>2501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the label column value spam and ham into 1 and o\n",
        "balanced_df['Label'] = pd.factorize(balanced_df['Label'])[0]"
      ],
      "metadata": {
        "id": "P6pJiiUGq9jU"
      },
      "id": "P6pJiiUGq9jU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split the dataset into train, validation and test\n",
        "def random_split(df, train_frac, val_frac):\n",
        "  #shuffle the dataset before sampling and reset the index\n",
        "  df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "  #calculate split ends\n",
        "  train_end = int(len(df)*train_frac)\n",
        "  val_end = train_end + int(len(df)*val_frac)\n",
        "\n",
        "  #split the dataset\n",
        "  train_df = df[:train_end]\n",
        "  validation_df = df[train_end:val_end]\n",
        "  test_df = df[val_end:]\n",
        "\n",
        "  return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wIqt4k4zvarI"
      },
      "id": "wIqt4k4zvarI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df), len(validation_df), len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuxYg-_wOj4F",
        "outputId": "21eaa6b3-6e57-47c1-93a3-0f919546e002"
      },
      "id": "fuxYg-_wOj4F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3501 500 1001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the dataset as csv format to use it later\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "4O0Tpe8Tvaoo"
      },
      "id": "4O0Tpe8Tvaoo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "#class to equalize the sequence length of all data input by padding eos tokenid\n",
        "class padding_dataset(Dataset):\n",
        "  def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "    #pretokenized text\n",
        "    self.encoded_texts = [tokenizer.encode(text) for text in self.data['Text']]\n",
        "\n",
        "    if max_length is None:\n",
        "      self.max_length = self._longest_encoded_length()\n",
        "    else:\n",
        "      self.max_length = max_length\n",
        "\n",
        "      #truncate sequences length to match with maximum length\n",
        "      self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
        "\n",
        "    #pad eos tokenid to sequences to match with maximum length\n",
        "    self.encoded_text = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts]\n",
        "\n",
        "  #returns encoded_text and label in tensor form\n",
        "  def __getitem__(self, index):\n",
        "    encoded = self.encoded_text[index]\n",
        "    label = self.data.iloc[index]['Label']\n",
        "\n",
        "    return(torch.tensor(encoded, dtype=torch.long),\n",
        "           torch.tensor(label, dtype=torch.long))\n",
        "\n",
        "  def __len__(self):\n",
        "    return(len(self.data))\n",
        "\n",
        "  #returns the sequence length containing max length\n",
        "  def _longest_encoded_length(self):\n",
        "    max_length=0\n",
        "    for encoded_text in self.encoded_texts:\n",
        "      encoded_length = len(encoded_text)\n",
        "      if encoded_length > max_length:\n",
        "        max_length = encoded_length\n",
        "    return max_length\n"
      ],
      "metadata": {
        "id": "maYvb3GrvamV"
      },
      "id": "maYvb3GrvamV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = padding_dataset(csv_file='train.csv', max_length=NEW_CONFIG[\"context_length\"], tokenizer=tokenizer)\n",
        "print(train_dataset.max_length)\n",
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubaMJ3EavajV",
        "outputId": "523ed3e7-0da9-4209-ecc2-e71ece4bee0f"
      },
      "id": "ubaMJ3EavajV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3501"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = padding_dataset(csv_file='test.csv', max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
        "val_dataset = padding_dataset(csv_file='validation.csv', max_length=train_dataset.max_length, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "j4pIxvruvagi"
      },
      "id": "j4pIxvruvagi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 25\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "#create a batches of dataset with max_length as sequence length and batch_size/total sequence per batch as 8\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)"
      ],
      "metadata": {
        "id": "Et-xnPg4vaaL"
      },
      "id": "Et-xnPg4vaaL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input, target in train_loader:\n",
        "  print(input.shape, target.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBeLSeChPSyk",
        "outputId": "a95bf16e-ecba-4bf1-fea4-02c7defeecf4"
      },
      "id": "aBeLSeChPSyk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25, 1024]) torch.Size([25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader) #total training batches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSDN4OhRq2PH",
        "outputId": "a915f254-02db-4e12-9677-2abdf2c95cea"
      },
      "id": "BSDN4OhRq2PH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we need to modify new pretrained model for classification finetuning\n",
        "#for that we have to modify output layer which map the hidden representation to vocabulary size\n",
        "#with a smaller ouput layer that maps two classes:0 (not spam),1(spam)\n",
        "print(gpt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvRDE-dzPSt3",
        "outputId": "e3919455-0ca0-454e-d9e0-25fd9f498508"
      },
      "id": "wvRDE-dzPSt3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTmodel(\n",
            "  (token_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make alllayers of gpt model non trainable to modify\n",
        "for param in gpt.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "#modify the output dimension of out_head\n",
        "torch.manual_seed(123)\n",
        "num_classes = 2\n",
        "gpt.out_head = torch.nn.Linear(NEW_CONFIG['emb_dim'], num_classes, bias=True).to(device)\n",
        "#by default require_grad is true for out_head"
      ],
      "metadata": {
        "id": "hdZKg3ccPSrj"
      },
      "id": "hdZKg3ccPSrj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the require_grad attribute true for last transformer block and for final normalization layer to make them trainable\n",
        "for param in gpt.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in gpt.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "IrV4-vv8PSo-"
      },
      "id": "IrV4-vv8PSo-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to calculate accuracy\n",
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "  model.eval()\n",
        "  correct_predictions, num_examples = 0, 0\n",
        "\n",
        "  if num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch, target_batch)in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = model(input_batch)[:,-1,:]\n",
        "      predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "      num_examples += predicted_labels.shape[0]\n",
        "      correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  return correct_predictions/num_examples\n"
      ],
      "metadata": {
        "id": "iIPI9lrKPSmh"
      },
      "id": "iIPI9lrKPSmh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to calculate loss of a batch but only of last token\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss\n",
        "\n",
        "#function to calculate loss of given batches\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ],
      "metadata": {
        "id": "NYJzxMRFPSkC"
      },
      "id": "NYJzxMRFPSkC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to train the model\n",
        "def train_classifier(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
        "  train_losses, val_losses, train_acc, val_acc = [], [], [], []\n",
        "  examples_seen, global_step = 0,0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      examples_seen += input_batch.shape[0]\n",
        "\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:4d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "      global_step += 1\n",
        "\n",
        "    #calculate accuracy after each epoch\n",
        "    train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "    val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "    print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "    train_acc.append(train_accuracy)\n",
        "    val_acc.append(val_accuracy)\n",
        "    global_step = 0\n",
        "\n",
        "  return train_losses, val_losses, train_acc, val_acc, examples_seen"
      ],
      "metadata": {
        "id": "bs4P2tngPShL"
      },
      "id": "bs4P2tngPShL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt.to(device)\n",
        "gpt.train()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(gpt.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier(gpt, train_loader, val_loader, optimizer, device,\n",
        "                                                                                 num_epochs=num_epochs, eval_freq=50, eval_iter=5)"
      ],
      "metadata": {
        "id": "suiMfxv2aKhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58caf9f-bba1-4711-c5ff-9ed62454642f"
      },
      "id": "suiMfxv2aKhf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step    0): Train loss 0.833, Val loss 0.787\n",
            "Ep 1 (Step   50): Train loss 0.658, Val loss 0.725\n",
            "Ep 1 (Step  100): Train loss 0.514, Val loss 0.637\n",
            "Training accuracy: 74.40% | Validation accuracy: 70.40%\n",
            "Ep 2 (Step    0): Train loss 0.510, Val loss 0.585\n",
            "Ep 2 (Step   50): Train loss 0.371, Val loss 0.454\n",
            "Ep 2 (Step  100): Train loss 0.299, Val loss 0.396\n",
            "Training accuracy: 87.20% | Validation accuracy: 83.20%\n",
            "Ep 3 (Step    0): Train loss 0.320, Val loss 0.382\n",
            "Ep 3 (Step   50): Train loss 0.302, Val loss 0.358\n",
            "Ep 3 (Step  100): Train loss 0.218, Val loss 0.278\n",
            "Training accuracy: 83.20% | Validation accuracy: 84.80%\n",
            "Ep 4 (Step    0): Train loss 0.297, Val loss 0.320\n",
            "Ep 4 (Step   50): Train loss 0.318, Val loss 0.315\n",
            "Ep 4 (Step  100): Train loss 0.234, Val loss 0.317\n",
            "Training accuracy: 94.40% | Validation accuracy: 91.20%\n",
            "Ep 5 (Step    0): Train loss 0.176, Val loss 0.234\n",
            "Ep 5 (Step   50): Train loss 0.175, Val loss 0.256\n",
            "Ep 5 (Step  100): Train loss 0.230, Val loss 0.407\n",
            "Training accuracy: 92.80% | Validation accuracy: 91.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to classify sms\n",
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "  model.eval()\n",
        "  input_ids = tokenizer.encode(text)\n",
        "  context_length = model.pos_emb.weight.shape[0]\n",
        "  if max_length is None:\n",
        "    new_length = context_length\n",
        "  else:\n",
        "    new_length = min(max_length,context_length)\n",
        "\n",
        "  input_ids = input_ids[:new_length]\n",
        "\n",
        "  input_ids += [pad_token_id] * (context_length - len(input_ids))\n",
        "  input_tensors = torch.tensor(input_ids, device=device).unsqueeze(0) #add batch dimension\n",
        "\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensors)[:,-1,:]\n",
        "  predicted_labels = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "  return \"spam\" if predicted_labels==1 else \"not spam\""
      ],
      "metadata": {
        "id": "Qs7nTc4DaKe4"
      },
      "id": "Qs7nTc4DaKe4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, gpt, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "id": "0Z-juRhmuikH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b023b9-40ff-428c-e69a-51adc8b9f7f6"
      },
      "id": "0Z-juRhmuikH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, gpt, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "id": "YvnoHE4Tuihp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8333d2-c832-4ebf-cf93-67d832c4b9dc"
      },
      "id": "YvnoHE4Tuihp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(gpt.state_dict(), \"review_classifier.pth\")"
      ],
      "metadata": {
        "id": "5RzVVXtfGz05"
      },
      "id": "5RzVVXtfGz05",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = torch.load(\"review_classifier.pth\")\n",
        "gpt.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_StnECiGzx5",
        "outputId": "c5c8100d-f814-41fc-e1cc-d91ec8d20b10"
      },
      "id": "J_StnECiGzx5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction Finetuning using Pretrained weights"
      ],
      "metadata": {
        "id": "3FXT3wN4W3zD"
      },
      "id": "3FXT3wN4W3zD"
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_355M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 1024,\n",
        "    \"n_heads\": 16,\n",
        "    \"n_layers\": 24,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": True\n",
        "}\n"
      ],
      "metadata": {
        "id": "q8Zvxl45elCf"
      },
      "id": "q8Zvxl45elCf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_medium = GPTmodel(GPT_CONFIG_355M)\n",
        "gpt_medium.eval();"
      ],
      "metadata": {
        "id": "rdduSsN6B8fa"
      },
      "id": "rdduSsN6B8fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load pretrained gpt2 model and tokenizer from huggingface transformers library\n",
        "model_name = 'gpt2-medium'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model_new = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "7667127cc244462886eaffe04c0fda8d",
            "d9b81007480c4318ae74291e48fc3a04",
            "75300d363b114a6084a8e501126a9897",
            "2339af9d03e64857b2ef7334808d41de",
            "fafa39a47cfc48f1b20d02ea8a4d47dd",
            "6c54fc0852ce44be83231bb7ae861147",
            "754d6264dc654d5086ae8136f4fae5df",
            "b137299d575c45a195e27a030b3e0c48",
            "9aa7f0a9a164491196eace5e72a363fa",
            "3d7c1242496b4f859092c717e38007f1",
            "d2510b15e4d64aff92270b0a9daec0f6",
            "6884389ebba849ef82f965e955052578",
            "3135daff6086420599783fe23c179a97",
            "82118123cc1043ff9be9ad6f72458c65",
            "addbf946fe8247b0854b2b9af6fdad8d",
            "c82a7f27161d4e6fb8d04414dd241466",
            "3215099272cd451f92a85e857f678517",
            "56785f833b504888a02f70a165feff56",
            "7dec8d1da1224301add6dc3caa044b39",
            "6c55637115864b61b6f16d09c21e2a9a",
            "a3242053e6404ba0bae126ecc5596137",
            "6a7b87f46bd74545936c9cc4bbf7a438",
            "edacc9fa049a40f590cc65d4cff9d21f",
            "c7228a0ed3c54b1fb7b38a7fe781d142",
            "555875eb8c0d43d7992017c3e58870e8",
            "1bd31081752c4131bae2de20ec7fa631",
            "b9fc766bb38842acb6610055e53c0aad",
            "65f18c5e292e4aa7a51140fcddbf62a2",
            "0ef41f8bc67f46b998f2e86b30a721b8",
            "bdc609ea96de493899368ee46a102e66",
            "52fcc6d2d930436e8cf575971066e87e",
            "935b4863bde64be484353a0651cad300",
            "fac80442e679418a8a8ad8040ae17419"
          ]
        },
        "id": "Ihc3pUOlelFV",
        "outputId": "6a2c1918-70c9-4297-8d5e-5495541a62bc"
      },
      "id": "Ihc3pUOlelFV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7667127cc244462886eaffe04c0fda8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6884389ebba849ef82f965e955052578"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edacc9fa049a40f590cc65d4cff9d21f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "FYqqQYehCdvF"
      },
      "id": "FYqqQYehCdvF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt_medium,model_new)\n",
        "gpt_medium.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6Vqx7R1pyHnJ",
        "outputId": "e77253e1-77c2-499a-d546-7c4f0a75b682"
      },
      "id": "6Vqx7R1pyHnJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTmodel(\n",
              "  (token_emb): Embedding(50257, 1024)\n",
              "  (pos_emb): Embedding(1024, 1024)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (12): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (13): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (14): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (15): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (16): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (17): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (18): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (19): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (20): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (21): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (22): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (23): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# with open('/content/drive/MyDrive/Dataset/email+sms+spam+collection/instruction-sms-data.json') as file:\n",
        "with open('/content/drive/MyDrive/Khanakh/Dataset/email+sms+spam+collection/instruction-sms-data.json') as file:\n",
        "  data = json.load(file)"
      ],
      "metadata": {
        "id": "R1ZvagVvVsTI"
      },
      "id": "R1ZvagVvVsTI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpcMmxwxVsQZ",
        "outputId": "64d29a4f-2c1d-4e2f-bb53-089a1b141a1a"
      },
      "id": "mpcMmxwxVsQZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1100"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNk2Yxq4b97j",
        "outputId": "1eeb677a-d474-42c6-8866-f5454a1721ed"
      },
      "id": "FNk2Yxq4b97j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.',\n",
              "  'input': 'freind --> friend',\n",
              "  'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'},\n",
              " {'instruction': 'Edit the following sentence for grammar.',\n",
              "  'input': 'He go to the park every day.',\n",
              "  'output': 'He goes to the park every day.'},\n",
              " {'instruction': 'Convert 45 kilometers to meters.',\n",
              "  'input': '',\n",
              "  'output': '45 kilometers is 45000 meters.'},\n",
              " {'instruction': \"Rewrite this sentence to start with 'Although': Despite the rain, they went for a walk.\",\n",
              "  'input': '',\n",
              "  'output': 'Although it was raining, they went for a walk.'},\n",
              " {'instruction': 'What are the first 10 square numbers?',\n",
              "  'input': '',\n",
              "  'output': '1, 4, 9, 16, 25, 36, 49, 64, 81, 100.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting text into alpaca format\n",
        "def format_input(entry):\n",
        "  instruction_text = (f\"Below is an instruction that describes a task. Write a response that appropriately completes \"\n",
        "                      f\"the request. \\n\\n### Instruction:\\n{entry['instruction']}\")\n",
        "  input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\" #skips if input is empty\n",
        "\n",
        "  return instruction_text + input_text"
      ],
      "metadata": {
        "id": "5NLBQ_PgVsN5"
      },
      "id": "5NLBQ_PgVsN5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting dataset into train-test-validation\n",
        "train_portion = int(len(data)*0.7) # 70%\n",
        "test_portion = int(len(data)*0.2) # 20%\n",
        "val_portion = len(data) - train_portion - test_portion # 10%\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion+test_portion]\n",
        "val_data = data[train_portion+test_portion:]"
      ],
      "metadata": {
        "id": "z9OSssDaVsLG"
      },
      "id": "z9OSssDaVsLG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "print(len(val_data))"
      ],
      "metadata": {
        "id": "t6u_G4oyVsHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e255984f-71d8-48b8-83db-3ddd80800cf9"
      },
      "id": "t6u_G4oyVsHs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "770\n",
            "220\n",
            "110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "#class to create a dataset and pass it to dataloader\n",
        "class InstructionDataset(Dataset):\n",
        "  def __init__(self, data, tokenizer):\n",
        "    self.data = data\n",
        "\n",
        "    #pretokenized text\n",
        "    self.encoded_text = []\n",
        "    for entry in self.data:\n",
        "      instruction_plus_input = format_input(entry)\n",
        "      response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "      full_text = instruction_plus_input + response_text\n",
        "      self.encoded_text.append(tokenizer.encode(full_text))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.encoded_text[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n"
      ],
      "metadata": {
        "id": "LZCE_6E2VsFA"
      },
      "id": "LZCE_6E2VsFA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create input target pairs and pad eot tokens and equalize them to -100 so they will not participate to calculate loss\n",
        "def custom_collate_fn(batch,  device, pad_token_id=50256, ignore_index=-100, allowed_max_length=None):\n",
        "  batch_max_length = max(len(item)+1 for item in batch)\n",
        "  batch_max_length = min(batch_max_length, allowed_max_length)\n",
        "  input_lst, target_lst = [], []\n",
        "\n",
        "  for item in batch:\n",
        "    new_item = item[:batch_max_length].copy()\n",
        "    new_item.append(pad_token_id)\n",
        "    padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
        "    input = torch.tensor(padded[:-1])\n",
        "    target = torch.tensor(padded[1:])\n",
        "\n",
        "    #replace all pad token to ignore index except first\n",
        "    mask = target == pad_token_id\n",
        "    indices = torch.nonzero(mask).squeeze()\n",
        "    if indices.numel() > 1:\n",
        "      target[indices[1:]] = ignore_index\n",
        "\n",
        "    input_lst.append(input)\n",
        "    target_lst.append(target)\n",
        "\n",
        "  #convert list of input and target to stack\n",
        "  input_tensors = torch.stack(input_lst).to(device)\n",
        "  target_tensors = torch.stack(target_lst).to(device)\n",
        "\n",
        "  return input_tensors, target_tensors\n"
      ],
      "metadata": {
        "id": "074zb_X3elH6"
      },
      "id": "074zb_X3elH6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length = GPT_CONFIG_355M['context_length'])"
      ],
      "metadata": {
        "id": "lNXcZ5jPVsBn"
      },
      "id": "lNXcZ5jPVsBn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 5\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, collate_fn=customized_collate_fn,\n",
        "                          shuffle=True, drop_last=True, num_workers=num_workers)\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, collate_fn=customized_collate_fn,\n",
        "                          shuffle=False, drop_last=False, num_workers=num_workers)\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=customized_collate_fn,\n",
        "                          shuffle=False, drop_last=False, num_workers=num_workers)"
      ],
      "metadata": {
        "id": "rc14g-ZTvHYe"
      },
      "id": "rc14g-ZTvHYe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5la3_dDh5fRe",
        "outputId": "06c78f62-aa33-4c74-cd67-2591fc347b15"
      },
      "id": "5la3_dDh5fRe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten(), ignore_index=-100)\n",
        "  return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "  total_loss = 0.\n",
        "  if len(data_loader) == 0:\n",
        "      return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "      num_batches = len(data_loader)\n",
        "  else:\n",
        "      # Reduce the number of batches to match the total number of batches in the data loader\n",
        "      # if num_batches exceeds the number of batches in the data loader\n",
        "      num_batches = min(num_batches, len(data_loader))\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "      if i < num_batches:\n",
        "          loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "          total_loss += loss.item()\n",
        "      else:\n",
        "          break\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "2tJ8o933vHVI"
      },
      "id": "2tJ8o933vHVI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
        "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "  tokens_seen, global_step = 0,0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += input_batch.numel()\n",
        "\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:4d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "      global_step += 1\n",
        "\n",
        "    global_step = 0\n",
        "\n",
        "  return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "Cyfm0fcZvHPM"
      },
      "id": "Cyfm0fcZvHPM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in gpt_medium.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# # unfreeze last blocks\n",
        "# for p in gpt_medium.trf_blocks[-1].parameters():\n",
        "#     p.requires_grad = True\n",
        "\n",
        "# unfreeze final norm + lm head\n",
        "for p in gpt_medium.final_norm.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "for p in gpt_medium.out_head.parameters():\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "8-G2shEU_L-q"
      },
      "id": "8-G2shEU_L-q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_medium.to(device)\n",
        "gpt_medium.train()\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(gpt_medium.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model(gpt_medium, train_loader, val_loader, optimizer, device,\n",
        "                                                    num_epochs=num_epochs, eval_freq=10, eval_iter=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFaDpYt6vHMQ",
        "outputId": "437eeecd-c60f-421e-db77-5aded2b16bf7"
      },
      "id": "MFaDpYt6vHMQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step    0): Train loss 3.884, Val loss 3.874\n",
            "Ep 1 (Step   10): Train loss 3.575, Val loss 3.575\n",
            "Ep 1 (Step   20): Train loss 3.285, Val loss 3.313\n",
            "Ep 1 (Step   30): Train loss 3.074, Val loss 3.091\n",
            "Ep 1 (Step   40): Train loss 2.831, Val loss 2.907\n",
            "Ep 1 (Step   50): Train loss 2.717, Val loss 2.747\n",
            "Ep 1 (Step   60): Train loss 2.562, Val loss 2.612\n",
            "Ep 1 (Step   70): Train loss 2.430, Val loss 2.496\n",
            "Ep 1 (Step   80): Train loss 2.356, Val loss 2.395\n",
            "Ep 1 (Step   90): Train loss 2.269, Val loss 2.304\n",
            "Ep 1 (Step  100): Train loss 2.129, Val loss 2.221\n",
            "Ep 1 (Step  110): Train loss 2.121, Val loss 2.147\n",
            "Ep 1 (Step  120): Train loss 2.026, Val loss 2.083\n",
            "Ep 1 (Step  130): Train loss 1.862, Val loss 2.025\n",
            "Ep 1 (Step  140): Train loss 1.830, Val loss 1.976\n",
            "Ep 1 (Step  150): Train loss 1.856, Val loss 1.934\n",
            "Ep 2 (Step    0): Train loss 1.832, Val loss 1.917\n",
            "Ep 2 (Step   10): Train loss 1.791, Val loss 1.879\n",
            "Ep 2 (Step   20): Train loss 1.723, Val loss 1.843\n",
            "Ep 2 (Step   30): Train loss 1.729, Val loss 1.814\n",
            "Ep 2 (Step   40): Train loss 1.705, Val loss 1.786\n",
            "Ep 2 (Step   50): Train loss 1.661, Val loss 1.760\n",
            "Ep 2 (Step   60): Train loss 1.599, Val loss 1.737\n",
            "Ep 2 (Step   70): Train loss 1.612, Val loss 1.715\n",
            "Ep 2 (Step   80): Train loss 1.602, Val loss 1.694\n",
            "Ep 2 (Step   90): Train loss 1.528, Val loss 1.673\n",
            "Ep 2 (Step  100): Train loss 1.556, Val loss 1.654\n",
            "Ep 2 (Step  110): Train loss 1.483, Val loss 1.636\n",
            "Ep 2 (Step  120): Train loss 1.459, Val loss 1.622\n",
            "Ep 2 (Step  130): Train loss 1.462, Val loss 1.608\n",
            "Ep 2 (Step  140): Train loss 1.399, Val loss 1.592\n",
            "Ep 2 (Step  150): Train loss 1.454, Val loss 1.578\n",
            "Ep 3 (Step    0): Train loss 1.385, Val loss 1.573\n",
            "Ep 3 (Step   10): Train loss 1.441, Val loss 1.558\n",
            "Ep 3 (Step   20): Train loss 1.346, Val loss 1.547\n",
            "Ep 3 (Step   30): Train loss 1.320, Val loss 1.534\n",
            "Ep 3 (Step   40): Train loss 1.373, Val loss 1.523\n",
            "Ep 3 (Step   50): Train loss 1.311, Val loss 1.511\n",
            "Ep 3 (Step   60): Train loss 1.331, Val loss 1.500\n",
            "Ep 3 (Step   70): Train loss 1.275, Val loss 1.492\n",
            "Ep 3 (Step   80): Train loss 1.272, Val loss 1.481\n",
            "Ep 3 (Step   90): Train loss 1.286, Val loss 1.470\n",
            "Ep 3 (Step  100): Train loss 1.360, Val loss 1.462\n",
            "Ep 3 (Step  110): Train loss 1.247, Val loss 1.453\n",
            "Ep 3 (Step  120): Train loss 1.270, Val loss 1.445\n",
            "Ep 3 (Step  130): Train loss 1.198, Val loss 1.439\n",
            "Ep 3 (Step  140): Train loss 1.210, Val loss 1.431\n",
            "Ep 3 (Step  150): Train loss 1.257, Val loss 1.423\n",
            "Ep 4 (Step    0): Train loss 1.207, Val loss 1.421\n",
            "Ep 4 (Step   10): Train loss 1.177, Val loss 1.418\n",
            "Ep 4 (Step   20): Train loss 1.206, Val loss 1.413\n",
            "Ep 4 (Step   30): Train loss 1.217, Val loss 1.407\n",
            "Ep 4 (Step   40): Train loss 1.209, Val loss 1.398\n",
            "Ep 4 (Step   50): Train loss 1.166, Val loss 1.388\n",
            "Ep 4 (Step   60): Train loss 1.184, Val loss 1.382\n",
            "Ep 4 (Step   70): Train loss 1.139, Val loss 1.380\n",
            "Ep 4 (Step   80): Train loss 1.153, Val loss 1.376\n",
            "Ep 4 (Step   90): Train loss 1.123, Val loss 1.368\n",
            "Ep 4 (Step  100): Train loss 1.129, Val loss 1.363\n",
            "Ep 4 (Step  110): Train loss 1.160, Val loss 1.359\n",
            "Ep 4 (Step  120): Train loss 1.074, Val loss 1.355\n",
            "Ep 4 (Step  130): Train loss 1.120, Val loss 1.349\n",
            "Ep 4 (Step  140): Train loss 1.143, Val loss 1.343\n",
            "Ep 4 (Step  150): Train loss 1.016, Val loss 1.339\n",
            "Ep 5 (Step    0): Train loss 0.999, Val loss 1.338\n",
            "Ep 5 (Step   10): Train loss 1.150, Val loss 1.335\n",
            "Ep 5 (Step   20): Train loss 1.133, Val loss 1.330\n",
            "Ep 5 (Step   30): Train loss 1.046, Val loss 1.325\n",
            "Ep 5 (Step   40): Train loss 1.144, Val loss 1.320\n",
            "Ep 5 (Step   50): Train loss 1.110, Val loss 1.317\n",
            "Ep 5 (Step   60): Train loss 1.108, Val loss 1.314\n",
            "Ep 5 (Step   70): Train loss 1.011, Val loss 1.313\n",
            "Ep 5 (Step   80): Train loss 1.068, Val loss 1.310\n",
            "Ep 5 (Step   90): Train loss 0.997, Val loss 1.306\n",
            "Ep 5 (Step  100): Train loss 1.059, Val loss 1.300\n",
            "Ep 5 (Step  110): Train loss 1.075, Val loss 1.296\n",
            "Ep 5 (Step  120): Train loss 1.070, Val loss 1.294\n",
            "Ep 5 (Step  130): Train loss 1.067, Val loss 1.288\n",
            "Ep 5 (Step  140): Train loss 0.969, Val loss 1.283\n",
            "Ep 5 (Step  150): Train loss 0.930, Val loss 1.281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses, tokens_seen = train_model(gpt_medium, train_loader, val_loader, optimizer, device,\n",
        "                                                    num_epochs=num_epochs, eval_freq=10, eval_iter=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylUyRNSyF8lv",
        "outputId": "7b72da67-b412-490c-8888-7fad49ad9b0e"
      },
      "id": "ylUyRNSyF8lv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step    0): Train loss 0.826, Val loss 1.176\n",
            "Ep 1 (Step   10): Train loss 0.831, Val loss 1.176\n",
            "Ep 1 (Step   20): Train loss 0.832, Val loss 1.179\n",
            "Ep 1 (Step   30): Train loss 0.745, Val loss 1.179\n",
            "Ep 1 (Step   40): Train loss 0.841, Val loss 1.177\n",
            "Ep 1 (Step   50): Train loss 0.855, Val loss 1.174\n",
            "Ep 1 (Step   60): Train loss 0.798, Val loss 1.173\n",
            "Ep 1 (Step   70): Train loss 0.815, Val loss 1.173\n",
            "Ep 1 (Step   80): Train loss 0.762, Val loss 1.173\n",
            "Ep 1 (Step   90): Train loss 0.697, Val loss 1.173\n",
            "Ep 1 (Step  100): Train loss 0.704, Val loss 1.172\n",
            "Ep 1 (Step  110): Train loss 0.774, Val loss 1.168\n",
            "Ep 1 (Step  120): Train loss 0.823, Val loss 1.166\n",
            "Ep 1 (Step  130): Train loss 0.720, Val loss 1.166\n",
            "Ep 1 (Step  140): Train loss 0.781, Val loss 1.166\n",
            "Ep 1 (Step  150): Train loss 0.788, Val loss 1.166\n",
            "Ep 2 (Step    0): Train loss 0.771, Val loss 1.166\n",
            "Ep 2 (Step   10): Train loss 0.755, Val loss 1.168\n",
            "Ep 2 (Step   20): Train loss 0.809, Val loss 1.168\n",
            "Ep 2 (Step   30): Train loss 0.774, Val loss 1.167\n",
            "Ep 2 (Step   40): Train loss 0.785, Val loss 1.167\n",
            "Ep 2 (Step   50): Train loss 0.750, Val loss 1.167\n",
            "Ep 2 (Step   60): Train loss 0.769, Val loss 1.167\n",
            "Ep 2 (Step   70): Train loss 0.750, Val loss 1.166\n",
            "Ep 2 (Step   80): Train loss 0.723, Val loss 1.165\n",
            "Ep 2 (Step   90): Train loss 0.778, Val loss 1.163\n",
            "Ep 2 (Step  100): Train loss 0.716, Val loss 1.162\n",
            "Ep 2 (Step  110): Train loss 0.724, Val loss 1.163\n",
            "Ep 2 (Step  120): Train loss 0.760, Val loss 1.163\n",
            "Ep 2 (Step  130): Train loss 0.727, Val loss 1.161\n",
            "Ep 2 (Step  140): Train loss 0.716, Val loss 1.158\n",
            "Ep 2 (Step  150): Train loss 0.774, Val loss 1.158\n",
            "Ep 3 (Step    0): Train loss 0.725, Val loss 1.158\n",
            "Ep 3 (Step   10): Train loss 0.806, Val loss 1.159\n",
            "Ep 3 (Step   20): Train loss 0.782, Val loss 1.159\n",
            "Ep 3 (Step   30): Train loss 0.678, Val loss 1.159\n",
            "Ep 3 (Step   40): Train loss 0.670, Val loss 1.158\n",
            "Ep 3 (Step   50): Train loss 0.734, Val loss 1.157\n",
            "Ep 3 (Step   60): Train loss 0.757, Val loss 1.155\n",
            "Ep 3 (Step   70): Train loss 0.750, Val loss 1.154\n",
            "Ep 3 (Step   80): Train loss 0.703, Val loss 1.155\n",
            "Ep 3 (Step   90): Train loss 0.766, Val loss 1.156\n",
            "Ep 3 (Step  100): Train loss 0.758, Val loss 1.155\n",
            "Ep 3 (Step  110): Train loss 0.754, Val loss 1.154\n",
            "Ep 3 (Step  120): Train loss 0.728, Val loss 1.154\n",
            "Ep 3 (Step  130): Train loss 0.714, Val loss 1.154\n",
            "Ep 3 (Step  140): Train loss 0.696, Val loss 1.154\n",
            "Ep 3 (Step  150): Train loss 0.702, Val loss 1.153\n",
            "Ep 4 (Step    0): Train loss 0.719, Val loss 1.152\n",
            "Ep 4 (Step   10): Train loss 0.688, Val loss 1.150\n",
            "Ep 4 (Step   20): Train loss 0.728, Val loss 1.151\n",
            "Ep 4 (Step   30): Train loss 0.670, Val loss 1.151\n",
            "Ep 4 (Step   40): Train loss 0.683, Val loss 1.150\n",
            "Ep 4 (Step   50): Train loss 0.707, Val loss 1.148\n",
            "Ep 4 (Step   60): Train loss 0.732, Val loss 1.147\n",
            "Ep 4 (Step   70): Train loss 0.727, Val loss 1.148\n",
            "Ep 4 (Step   80): Train loss 0.711, Val loss 1.148\n",
            "Ep 4 (Step   90): Train loss 0.700, Val loss 1.149\n",
            "Ep 4 (Step  100): Train loss 0.672, Val loss 1.152\n",
            "Ep 4 (Step  110): Train loss 0.769, Val loss 1.152\n",
            "Ep 4 (Step  120): Train loss 0.793, Val loss 1.151\n",
            "Ep 4 (Step  130): Train loss 0.665, Val loss 1.150\n",
            "Ep 4 (Step  140): Train loss 0.703, Val loss 1.149\n",
            "Ep 4 (Step  150): Train loss 0.737, Val loss 1.149\n",
            "Ep 5 (Step    0): Train loss 0.697, Val loss 1.150\n",
            "Ep 5 (Step   10): Train loss 0.654, Val loss 1.151\n",
            "Ep 5 (Step   20): Train loss 0.739, Val loss 1.149\n",
            "Ep 5 (Step   30): Train loss 0.671, Val loss 1.148\n",
            "Ep 5 (Step   40): Train loss 0.745, Val loss 1.147\n",
            "Ep 5 (Step   50): Train loss 0.681, Val loss 1.147\n",
            "Ep 5 (Step   60): Train loss 0.722, Val loss 1.148\n",
            "Ep 5 (Step   70): Train loss 0.699, Val loss 1.148\n",
            "Ep 5 (Step   80): Train loss 0.641, Val loss 1.146\n",
            "Ep 5 (Step   90): Train loss 0.668, Val loss 1.143\n",
            "Ep 5 (Step  100): Train loss 0.670, Val loss 1.141\n",
            "Ep 5 (Step  110): Train loss 0.689, Val loss 1.141\n",
            "Ep 5 (Step  120): Train loss 0.661, Val loss 1.141\n",
            "Ep 5 (Step  130): Train loss 0.738, Val loss 1.143\n",
            "Ep 5 (Step  140): Train loss 0.677, Val loss 1.144\n",
            "Ep 5 (Step  150): Train loss 0.695, Val loss 1.142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(gpt_medium.state_dict(), \"review_instruction1.pth\")"
      ],
      "metadata": {
        "id": "LL18r0s6Vr-m"
      },
      "id": "LL18r0s6Vr-m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = torch.load(\"review_instruction.pth\")\n",
        "gpt_medium.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "id": "VqEpLknW0qMo"
      },
      "id": "VqEpLknW0qMo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = format_input(train_data[0])\n",
        "generate_and_print(gpt_medium, tokenizer, device, start_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7T_0BOI0qJs",
        "outputId": "bbfdf2c6-b646-48bd-e929-ae8914e70dfc"
      },
      "id": "v7T_0BOI0qJs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.   ### Instruction: Evaluate the following phrase by transforming it into the spelling given.  ### Input: freind --> friend.  ### Response: The spelling of 'friend' is 'freind'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I0_GaAlJIl-m"
      },
      "id": "I0_GaAlJIl-m",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e8e57657d01444fb53099dd1ad9e91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06c60e5ddd2a44749be0cf496728bd41",
              "IPY_MODEL_c52014e636644a8bbf36af7a0e675cfd",
              "IPY_MODEL_6602fc5721c445a3b93a9beaae2be4a1"
            ],
            "layout": "IPY_MODEL_51306772f89d42ccbf94a28c659a98b4"
          }
        },
        "06c60e5ddd2a44749be0cf496728bd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc8d444b7414eb1b091f93bb39a66dd",
            "placeholder": "​",
            "style": "IPY_MODEL_a27d25b2c08845f18cc3eab0aa1c0675",
            "value": "config.json: 100%"
          }
        },
        "c52014e636644a8bbf36af7a0e675cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e3509c630af4e1d93537834766f78d2",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9725d1c35c8c479a9ce5c049f88ffe80",
            "value": 665
          }
        },
        "6602fc5721c445a3b93a9beaae2be4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ddfab07551c44df87e1f8faddacdeee",
            "placeholder": "​",
            "style": "IPY_MODEL_e6639aa8a55b4b77994361650a381a9b",
            "value": " 665/665 [00:00&lt;00:00, 77.1kB/s]"
          }
        },
        "51306772f89d42ccbf94a28c659a98b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc8d444b7414eb1b091f93bb39a66dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a27d25b2c08845f18cc3eab0aa1c0675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e3509c630af4e1d93537834766f78d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9725d1c35c8c479a9ce5c049f88ffe80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ddfab07551c44df87e1f8faddacdeee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6639aa8a55b4b77994361650a381a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a6f8f46126e4cb78aaedcd70e74a200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1654069382b4c04ad5ab480eaaaba51",
              "IPY_MODEL_4cd195d22eed491f98bdc63b6d851a4f",
              "IPY_MODEL_fc0585a1666d4b0a8f5c6c0fca74d18b"
            ],
            "layout": "IPY_MODEL_4dc468f4667d460c82dd17f15c0f0857"
          }
        },
        "a1654069382b4c04ad5ab480eaaaba51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5761439544f44d3984fbbc6e9573c9e9",
            "placeholder": "​",
            "style": "IPY_MODEL_d6db2b44f7674bb09ad100c4464a8776",
            "value": "model.safetensors: 100%"
          }
        },
        "4cd195d22eed491f98bdc63b6d851a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e7d69871aeb44a284e28ff08de32986",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8998c0820454e6b8029a22d97b4dced",
            "value": 548105171
          }
        },
        "fc0585a1666d4b0a8f5c6c0fca74d18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e590edaaf634a869031e4c0d4f25599",
            "placeholder": "​",
            "style": "IPY_MODEL_bef84d2ca11042ceaa7b08bcefb5e838",
            "value": " 548M/548M [00:02&lt;00:00, 296MB/s]"
          }
        },
        "4dc468f4667d460c82dd17f15c0f0857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5761439544f44d3984fbbc6e9573c9e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6db2b44f7674bb09ad100c4464a8776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e7d69871aeb44a284e28ff08de32986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8998c0820454e6b8029a22d97b4dced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e590edaaf634a869031e4c0d4f25599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef84d2ca11042ceaa7b08bcefb5e838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e17e99481464471b0d5622b2860b2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6aca18f95f6437fb83e9913be450adf",
              "IPY_MODEL_8d536187aa8d4bc0b54a78bc489c2c90",
              "IPY_MODEL_bcb05f1d439c4b07ae5984a8f85bb6cf"
            ],
            "layout": "IPY_MODEL_90e3c047db144ae7bca91e7b971ee2c0"
          }
        },
        "a6aca18f95f6437fb83e9913be450adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2d24b5281004f7ca9775ac59892a264",
            "placeholder": "​",
            "style": "IPY_MODEL_f56504e73df94cc8a2adefda81cc6f24",
            "value": "generation_config.json: 100%"
          }
        },
        "8d536187aa8d4bc0b54a78bc489c2c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3ea7d7d619f4754946c58d9955d6fd6",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd384d195df64b9cb6d34e29fd85d66b",
            "value": 124
          }
        },
        "bcb05f1d439c4b07ae5984a8f85bb6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bf34e95ca334295a3ee5063f49dc56b",
            "placeholder": "​",
            "style": "IPY_MODEL_06d276641e77412cbc372d27142e1f55",
            "value": " 124/124 [00:00&lt;00:00, 8.39kB/s]"
          }
        },
        "90e3c047db144ae7bca91e7b971ee2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d24b5281004f7ca9775ac59892a264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56504e73df94cc8a2adefda81cc6f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3ea7d7d619f4754946c58d9955d6fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd384d195df64b9cb6d34e29fd85d66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bf34e95ca334295a3ee5063f49dc56b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d276641e77412cbc372d27142e1f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7667127cc244462886eaffe04c0fda8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9b81007480c4318ae74291e48fc3a04",
              "IPY_MODEL_75300d363b114a6084a8e501126a9897",
              "IPY_MODEL_2339af9d03e64857b2ef7334808d41de"
            ],
            "layout": "IPY_MODEL_fafa39a47cfc48f1b20d02ea8a4d47dd"
          }
        },
        "d9b81007480c4318ae74291e48fc3a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c54fc0852ce44be83231bb7ae861147",
            "placeholder": "​",
            "style": "IPY_MODEL_754d6264dc654d5086ae8136f4fae5df",
            "value": "config.json: 100%"
          }
        },
        "75300d363b114a6084a8e501126a9897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b137299d575c45a195e27a030b3e0c48",
            "max": 718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9aa7f0a9a164491196eace5e72a363fa",
            "value": 718
          }
        },
        "2339af9d03e64857b2ef7334808d41de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d7c1242496b4f859092c717e38007f1",
            "placeholder": "​",
            "style": "IPY_MODEL_d2510b15e4d64aff92270b0a9daec0f6",
            "value": " 718/718 [00:00&lt;00:00, 61.3kB/s]"
          }
        },
        "fafa39a47cfc48f1b20d02ea8a4d47dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c54fc0852ce44be83231bb7ae861147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "754d6264dc654d5086ae8136f4fae5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b137299d575c45a195e27a030b3e0c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa7f0a9a164491196eace5e72a363fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d7c1242496b4f859092c717e38007f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2510b15e4d64aff92270b0a9daec0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6884389ebba849ef82f965e955052578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3135daff6086420599783fe23c179a97",
              "IPY_MODEL_82118123cc1043ff9be9ad6f72458c65",
              "IPY_MODEL_addbf946fe8247b0854b2b9af6fdad8d"
            ],
            "layout": "IPY_MODEL_c82a7f27161d4e6fb8d04414dd241466"
          }
        },
        "3135daff6086420599783fe23c179a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3215099272cd451f92a85e857f678517",
            "placeholder": "​",
            "style": "IPY_MODEL_56785f833b504888a02f70a165feff56",
            "value": "model.safetensors: 100%"
          }
        },
        "82118123cc1043ff9be9ad6f72458c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dec8d1da1224301add6dc3caa044b39",
            "max": 1519984962,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c55637115864b61b6f16d09c21e2a9a",
            "value": 1519984962
          }
        },
        "addbf946fe8247b0854b2b9af6fdad8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3242053e6404ba0bae126ecc5596137",
            "placeholder": "​",
            "style": "IPY_MODEL_6a7b87f46bd74545936c9cc4bbf7a438",
            "value": " 1.52G/1.52G [00:19&lt;00:00, 74.8MB/s]"
          }
        },
        "c82a7f27161d4e6fb8d04414dd241466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3215099272cd451f92a85e857f678517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56785f833b504888a02f70a165feff56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dec8d1da1224301add6dc3caa044b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c55637115864b61b6f16d09c21e2a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3242053e6404ba0bae126ecc5596137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7b87f46bd74545936c9cc4bbf7a438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edacc9fa049a40f590cc65d4cff9d21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7228a0ed3c54b1fb7b38a7fe781d142",
              "IPY_MODEL_555875eb8c0d43d7992017c3e58870e8",
              "IPY_MODEL_1bd31081752c4131bae2de20ec7fa631"
            ],
            "layout": "IPY_MODEL_b9fc766bb38842acb6610055e53c0aad"
          }
        },
        "c7228a0ed3c54b1fb7b38a7fe781d142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f18c5e292e4aa7a51140fcddbf62a2",
            "placeholder": "​",
            "style": "IPY_MODEL_0ef41f8bc67f46b998f2e86b30a721b8",
            "value": "generation_config.json: 100%"
          }
        },
        "555875eb8c0d43d7992017c3e58870e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdc609ea96de493899368ee46a102e66",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52fcc6d2d930436e8cf575971066e87e",
            "value": 124
          }
        },
        "1bd31081752c4131bae2de20ec7fa631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_935b4863bde64be484353a0651cad300",
            "placeholder": "​",
            "style": "IPY_MODEL_fac80442e679418a8a8ad8040ae17419",
            "value": " 124/124 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "b9fc766bb38842acb6610055e53c0aad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f18c5e292e4aa7a51140fcddbf62a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef41f8bc67f46b998f2e86b30a721b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdc609ea96de493899368ee46a102e66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52fcc6d2d930436e8cf575971066e87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "935b4863bde64be484353a0651cad300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac80442e679418a8a8ad8040ae17419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}